{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Poisson_dependent_time_v2.ipynb","provenance":[{"file_id":"1_egCADex-CWBlSIoePlqEDEdwbuAfXeU","timestamp":1607827958369},{"file_id":"1XMV7jyIB_jwndk0Bv8fstaMf6PDgs7jz","timestamp":1606298163020},{"file_id":"1y1QtT4hzrsTvXuS16vH7rxdDXmhKdLE9","timestamp":1605343337980}],"collapsed_sections":[],"mount_file_id":"1y1QtT4hzrsTvXuS16vH7rxdDXmhKdLE9","authorship_tag":"ABX9TyMudjUCET+/pO6wxX2woafq"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"A5BTg6fnUBZD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608259821199,"user_tz":360,"elapsed":965,"user":{"displayName":"duy pham","photoUrl":"","userId":"13182125700906094592"}},"outputId":"e47d3289-c7ad-4970-ec90-3024501d899e"},"source":["import numpy as np\n","import os\n","import cv2\n","import csv\n","import matplotlib.pyplot as plt\n","import math\n","import sys\n","import scipy.io\n","from scipy.interpolate import griddata\n","import time\n","from itertools import product, combinations\n","from mpl_toolkits.mplot3d import Axes3D\n","from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n","from mpl_toolkits.axes_grid1 import make_axes_locatable\n","import matplotlib.gridspec as gridspec\n","import matplotlib.ticker as mtick\n","%tensorflow_version 1.x\n","import tensorflow as tf\n","print(tf.__version__)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1.15.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"D0WGyU7Pjvmu"},"source":["np.random.seed(1234)\n","tf.set_random_seed(1234)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SnUoBdGrUe4V"},"source":["def initial_learning_rate(epoch):\n","    if (epoch >= 0) and (epoch < 500):\n","        return 0.01\n","    if (epoch >= 500) and (epoch < 1000):\n","        return 0.001\n","    else:\n","        return 0.0001"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IkNEr-JrUh7y"},"source":["class PDENet:\n","    # Init\n","    def __init__(self, xb, yb, tb, ub, xi, yi, ti, ui, x, y, t, layers):\n","        \n","        self.dim = 3\n","        \n","        self.xb = xb\n","        self.yb = yb\n","        self.tb = tb\n","        self.ub = ub\n","        self.xi = xi\n","        self.yi = yi\n","        self.ti = ti\n","        self.ui = ui\n","        self.x = x\n","        self.y = y\n","        self.t = t\n","        self.layers = layers\n","        \n","        # Initialize NN\n","        self.weights, self.biases = self.init_NN(layers)\n","        \n","        # Initialize parameters\n","        # self.lambda_1 = tf.Variable([0.0], dtype=tf.float32)\n","        # self.lambda_2 = tf.Variable([0.0], dtype=tf.float32)\n","        \n","        # tf placeholders and graph\n","        self.sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True,\n","                                                     log_device_placement=True))\n","        \n","        self.xytb_tf = tf.placeholder(tf.float32, shape=[None, 3, 1])\n","        self.ub_tf = tf.placeholder(tf.float32, shape=[None, 1])\n","\n","        self.xyti_tf = tf.placeholder(tf.float32, shape=[None, 3, 1])\n","        self.ui_tf = tf.placeholder(tf.float32, shape=[None, 1])\n","\n","        self.xyt_tf = tf.placeholder(tf.float32, shape=[None, 3, 1])\n","\n","        self.ub_pred, _ , _ , _ = self.net_u(self.xytb_tf)\n","        self.ui_pred, _ , _ , _ = self.net_u(self.xyti_tf)\n","        _ , self.f_u_pred = self.net_f_u(self.xyt_tf)\n","        \n","        self.loss = tf.reduce_mean(tf.square(self.ub_tf - self.ub_pred)) + \\\n","                    tf.reduce_mean(tf.square(self.ui_tf - self.ui_pred)) + \\\n","                    tf.reduce_mean(tf.square(self.f_u_pred))\n","                    \n","        self.optimizer = tf.contrib.opt.ScipyOptimizerInterface(self.loss, \n","                                                                method = 'L-BFGS-B', \n","                                                                options = {'maxiter': 3000,\n","                                                                           'maxfun': 50000,\n","                                                                           'maxcor': 50,\n","                                                                           'maxls': 50,\n","                                                                           'ftol' : 1.0 * np.finfo(float).eps})    \n","        self.lossHistogram = []  \n","        # self.adaptive_rate = tf.placeholder(tf.float32)\n","        self.optimizer_Adam = tf.train.AdamOptimizer(learning_rate= 0.001)\n","        self.train_op_Adam = self.optimizer_Adam.minimize(self.loss)                  \n","        \n","        init = tf.global_variables_initializer()\n","        self.sess.run(init)\n","\n","    def init_NN(self, layers):\n","        dim = self.dim\n","        weights = []\n","        biases = []\n","        num_layers = len(layers)\n","        W = self.xavier_init(size=[layers[0], dim])\n","        b = tf.Variable(tf.zeros([layers[0],1], dtype=tf.float32), dtype=tf.float32)\n","        weights.append(W)  \n","        biases.append(b)\n","        for l in range(1,num_layers-1):\n","            W = self.xavier_init(size=[layers[l], layers[l]])\n","            b = tf.Variable(tf.zeros([layers[l],1], dtype=tf.float32), dtype=tf.float32)\n","            weights.append(W)\n","            biases.append(b)  \n","        W = self.xavier_init(size=[1, layers[-1]])\n","        b = tf.Variable(tf.zeros([1,1], dtype=tf.float32), dtype=tf.float32)\n","        weights.append(W)  \n","        biases.append(b) \n","        return weights, biases\n","        \n","    def xavier_init(self, size):\n","        in_dim = size[0]\n","        out_dim = size[1]        \n","        xavier_stddev = np.sqrt(2/(in_dim + out_dim))\n","        return tf.Variable(tf.truncated_normal([in_dim, out_dim], stddev=xavier_stddev), dtype=tf.float32)\n","    \n","    def net_nn(self, X, weights, biases):\n","        num_layers = len(self.layers)\n","        S = X\n","        for l in range(0,num_layers-1):\n","            W = weights[l]\n","            b = biases[l]\n","            S = tf.tanh(tf.add(tf.matmul(W, S), b))\n","        W = weights[-1]\n","        b = biases[-1]\n","        S = tf.add(tf.matmul(W, S), b)\n","        return S\n","\n","    def net_u(self, xyt):\n","        u = self.net_nn(xyt, self.weights, self.biases)\n","        u = u[:,0]\n","        grad = tf.gradients(u, xyt)[0]\n","        u_x = grad[:,0]\n","        u_y = grad[:,1]\n","        u_t = grad[:,2]\n","        return u, u_x, u_y, u_t\n","        \n","    def net_f_u(self, xyt):\n","        u, u_x, u_y, u_t = self.net_u(xyt)\n","\n","        u_xx = tf.gradients(u_x, xyt)[0][:,0]\n","        u_yy = tf.gradients(u_y, xyt)[0][:,1]\n","\n","        f_u = u_t - (u_xx + u_yy) - (1+2.0*np.pi*np.pi)*tf.math.exp(xyt[:,2])*tf.math.sin(np.pi*xyt[:,0])*tf.math.sin(np.pi*xyt[:,1])\n","        \n","        return u, f_u\n","    \n","    def callback(self, loss):\n","        print('Loss: %.3e' % (loss))\n","        self.lossHistogram.append(loss)\n","      \n","    def train(self, nIter): \n","\n","        tf_dict = {self.xytb_tf: np.concatenate([self.xb, self.yb, self.tb], 1), self.ub_tf: self.ub,\n","                   self.xyti_tf: np.concatenate([self.xi, self.yi, self.ti], 1), self.ui_tf: self.ui,\n","                   self.xyt_tf: np.concatenate([self.x, self.y, self.t], 1)}\n","        \n","        start_time = time.time()\n","        for it in range(nIter):\n","            self.sess.run(self.train_op_Adam, tf_dict)\n","            \n","            # Print\n","            # if it % 10 == 0:\n","            elapsed = time.time() - start_time\n","            loss_value = self.sess.run(self.loss, tf_dict)\n","            print('It: %d, Loss: %.3e, Time: %.2f' % \n","                    (it, loss_value, elapsed))\n","            self.lossHistogram.append(loss_value)\n","            start_time = time.time()\n","\n","        self.optimizer.minimize(self.sess,\n","                                feed_dict = tf_dict,\n","                                fetches = [self.loss],\n","                                loss_callback = self.callback)\n","    \n","    def predict(self, x, y, t):\n","        \n","        tf_dict = {self.xytb_tf: np.concatenate([x, y, t], 1)}\n","        \n","        u = self.sess.run(self.ub_pred, tf_dict)\n","\n","        # tf_dict = {self.x_tf: x, self.y_tf: y}\n","        \n","        # f_u = self.sess.run(self.f_u_pred, tf_dict)\n","        \n","        return u"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RZVxA80L5IWv"},"source":["class sampling_from_rectangle:\n","    def __init__(self, x_range, y_range, t_range):\n","        self.x_range = x_range\n","        self.y_range = y_range\n","        self.t_range = t_range\n","\n","    def initial_samples(self, batchsize):\n","        # batchsize = int(batchsize/10)\n","        init_draw_x = np.random.uniform(self.x_range[0], self.x_range[1], batchsize)\n","        init_draw_y = np.random.uniform(self.y_range[0], self.y_range[1], batchsize)\n","        init_draw_t = np.random.uniform(self.t_range[0], self.t_range[0], batchsize)\n","\n","        return init_draw_x, init_draw_y, init_draw_t\n","\n","    def interior_samples(self, batchsize):\n","        int_draw_x = np.random.uniform(self.x_range[0], self.x_range[1], batchsize)\n","        int_draw_y = np.random.uniform(self.y_range[0], self.y_range[1], batchsize)\n","        int_draw_t = np.random.uniform(self.t_range[0], self.t_range[1], batchsize)\n","\n","        return int_draw_x, int_draw_y, int_draw_t\n","\n","    def boundary_samples(self, batchsize):\n","        # batchsize = int(batchsize/3)\n","        a = self.x_range[1]-self.x_range[0]\n","        b = self.y_range[1]-self.y_range[0]\n","\n","        draw_perimeter = np.random.uniform(0, 2*(a + b), batchsize)\n","\n","        draw = []\n","\n","        for i in draw_perimeter:\n","            if i < a:\n","                draw.append([i+ self.x_range[0], self.y_range[0]])\n","            elif a <= i and i < a+b:\n","                draw.append([self.x_range[1], (i-a) + self.y_range[0]])\n","            elif a+b <= i and i < 2*a+b:\n","                draw.append([self.x_range[1] - (i-(a+b)), self.y_range[1]])\n","            elif 2*a+b <= i and i<= 2*a+2*b:\n","                draw.append([self.x_range[0], self.y_range[1] - (i-(2*a+b))])\n","\n","        bound_draw_t = np.random.uniform(self.t_range[0], self.t_range[1], batchsize)\n","        return np.array(draw)[:, 0], np.array(draw)[:, 1], bound_draw_t"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yT1aEy_0HdmN","executionInfo":{"status":"ok","timestamp":1608260643611,"user_tz":360,"elapsed":971,"user":{"displayName":"duy pham","photoUrl":"","userId":"13182125700906094592"}},"outputId":"8a5564b1-5dcb-43af-e990-dcc14c61a2c3"},"source":["sampler = sampling_from_rectangle([0.0, 1.0], [0.0, 1.0], [0.0, 1.0])\r\n","N = 2000;\r\n","filename = 'data_'\r\n","\r\n","with open(filename + str(N) + '.csv', mode='w') as f:\r\n","    csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\r\n","\r\n","    bou_draw_x, bou_draw_y, bou_draw_t = sampler.boundary_samples(N)\r\n","    int_draw_x, int_draw_y, int_draw_t = sampler.interior_samples(N)\r\n","    init_draw_x, init_draw_y, init_draw_t = sampler.initial_samples(N)\r\n","    \r\n","    for i in range(N):\r\n","        csv_writer.writerow([int_draw_x[i], int_draw_y[i], int_draw_t[i],\r\n","                             bou_draw_x[i], bou_draw_y[i], bou_draw_t[i], 0.0, \r\n","                             init_draw_x[i], init_draw_y[i], init_draw_t[i], np.sin(np.pi*init_draw_x[i])*np.sin(np.pi*init_draw_y[i])])\r\n","\r\n","dataset = np.genfromtxt('data_2000.csv', delimiter=',')\r\n","print(dataset)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[0.58900704 0.44933121 0.21799792 ... 0.74865871 0.         0.70654502]\n"," [0.42786014 0.96243047 0.10662169 ... 0.91409094 0.         0.04547773]\n"," [0.85409391 0.6633909  0.95711985 ... 0.3066197  0.         0.60325935]\n"," ...\n"," [0.85437496 0.8352649  0.74123133 ... 0.45985962 0.         0.14423915]\n"," [0.15776623 0.94465303 0.27648917 ... 0.72699333 0.         0.75341154]\n"," [0.75415449 0.57808173 0.15503294 ... 0.850605   0.         0.26975895]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E0KHgVk5bA6M","executionInfo":{"status":"ok","timestamp":1608002581750,"user_tz":-420,"elapsed":950,"user":{"displayName":"duy pham","photoUrl":"","userId":"13182125700906094592"}},"outputId":"b8bc761c-13c6-4535-defb-43cafe5f5315"},"source":["dataset[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.84518147, 0.86138164, 0.77991124, 0.72351165, 0.        ,\n","       0.62776126, 0.        , 0.65210576, 0.0281263 , 0.        ,\n","       0.07836141])"]},"metadata":{"tags":[]},"execution_count":49}]},{"cell_type":"code","metadata":{"id":"wIKcRyELVhzK"},"source":["def flatArr(x):\n","    y = []\n","    for row in x:\n","        for el in row:\n","            y.append(el)\n","    return np.array(y).flatten()\n","\n","def splitData(data):\n","    x = []\n","    y = []\n","    xb = []\n","    yb = []\n","    ub = []\n","    u = []\n","    for row in data:\n","        if (row[0] == 0. or row[1] == 0. or row[0] == 1. or row[1] == 1.):\n","            xb.append(row[0])\n","            yb.append(row[1])\n","            ub.append(0.0)\n","        else:\n","            x.append(row[0])\n","            y.append(row[1])\n","            u.append(round(np.sin(np.pi*row[0])*np.sin(np.pi*row[1]), 6))\n","    return np.array(x), np.array(y), np.array(u), np.array(xb), np.array(yb), np.array(ub)\n","\n","def sample(T, delta_t, data):\n","    xi,yi,ui,xb,yb,ub = splitData(data)\n","    x_arr = np.array([])\n","    y_arr = np.array([])\n","    NT = np.int(T/delta_t)\n","    t = []\n","    for i in range(NT):\n","        t.append([round((i+1)*delta_t,6) for e in range(xi.size)])\n","        x_arr = np.concatenate((x_arr, xi))\n","        y_arr = np.concatenate((y_arr, yi))\n","    t = flatArr(t)\n","    tb = []\n","    xb_arr = np.array([])\n","    yb_arr = np.array([])\n","    for i in range(NT+1):\n","        tb.append([round(i*delta_t,6) for e in range(xb.size)])\n","        xb_arr = np.concatenate((xb_arr, xb))\n","        yb_arr = np.concatenate((yb_arr, yb))\n","    tb = flatArr(tb)\n","    ti = np.array([0.0 for e in range(xi.size)])\n","    ub = np.array([0.0 for e in xb_arr])\n","\n","    return x_arr, y_arr, t, xi, yi, ti, ui, xb_arr, yb_arr, tb, ub"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WbNnECPa62Ho"},"source":["# test\n","T = 1\n","delta_t = 0.5\n","xi = np.array([1.0 for e in range(3)])\n","yi = np.array([0.0 for e in range(3)])\n","x_arr = np.array([])\n","y_arr = np.array([])\n","NT = np.int(T/delta_t)\n","t = []\n","for i in range(NT):\n","    t.append([round((i+1)*delta_t,6) for e in range(xi.size)])\n","    x_arr = np.concatenate((x_arr, xi))\n","    y_arr = np.concatenate((y_arr, yi))\n","t = flatArr(t)\n","tb = []\n","xb_arr = np.array([])\n","yb_arr = np.array([])\n","for i in range(NT+1):\n","    tb.append([round(i*delta_t,6) for e in range(xi.size)])\n","    xb_arr = np.concatenate((xb_arr, xi))\n","    yb_arr = np.concatenate((yb_arr, yi))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dNt9KH73oJ15","executionInfo":{"status":"ok","timestamp":1608269103997,"user_tz":360,"elapsed":937,"user":{"displayName":"duy pham","photoUrl":"","userId":"13182125700906094592"}}},"source":["dataset = np.genfromtxt('test_data.txt', delimiter=',')\n","x, y, t, xi, yi, ti, ui, xb, yb, tb, ub = sample(1.0, 0.01, dataset)\n","x = x.reshape((x.size, 1, 1))\n","y = y.reshape((y.size, 1, 1))\n","t = t.reshape((t.size, 1, 1))\n","xb = xb.reshape((xb.size, 1, 1))\n","yb = yb.reshape((yb.size, 1, 1))\n","tb = tb.reshape((tb.size, 1, 1))\n","ub = ub.reshape((ub.size, 1))\n","xi = xi.reshape((xi.size, 1, 1))\n","yi = yi.reshape((yi.size, 1, 1))\n","ti = ti.reshape((ti.size, 1, 1))\n","ui = ui.reshape((ui.size, 1))\n","layers = [16, 16, 16, 16]\n","\n"],"execution_count":71,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8fJp_8cZr1J3","executionInfo":{"status":"ok","timestamp":1608264681613,"user_tz":360,"elapsed":963,"user":{"displayName":"duy pham","photoUrl":"","userId":"13182125700906094592"}},"outputId":"eda2128f-bc87-4110-f947-aa1e90fd86aa"},"source":["x.size"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["32400"]},"metadata":{"tags":[]},"execution_count":46}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yv39E0xFFT3a","executionInfo":{"status":"ok","timestamp":1608264682101,"user_tz":360,"elapsed":655,"user":{"displayName":"duy pham","photoUrl":"","userId":"13182125700906094592"}},"outputId":"ae683eb5-b213-4436-9bd3-6d901132198a"},"source":["xb.size"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["7676"]},"metadata":{"tags":[]},"execution_count":47}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SEBmM8h4FVjH","executionInfo":{"status":"ok","timestamp":1608264683035,"user_tz":360,"elapsed":805,"user":{"displayName":"duy pham","photoUrl":"","userId":"13182125700906094592"}},"outputId":"1b800fe6-de90-4e1e-9b4f-a75878f8b6e7"},"source":["xi.size"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["324"]},"metadata":{"tags":[]},"execution_count":48}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"EdrlTE8jqrgA","executionInfo":{"status":"ok","timestamp":1608270517271,"user_tz":360,"elapsed":1412198,"user":{"displayName":"duy pham","photoUrl":"","userId":"13182125700906094592"}},"outputId":"8b5f01d3-370d-4488-f3e6-50fad40e5a47"},"source":["model = PDENet(xb, yb, tb, ub, xi, yi, ti, ui, x, y, t, layers)\n","# model = PDENet(xb, yb, tb, ub, x, y, t, layers)\n","start_time = time.time()                \n","model.train(0)\n","elapsed = time.time() - start_time                \n","print('Training time: %.4f' % (elapsed))\n","losses = np.array(model.lossHistogram)\n","losses = losses.reshape(len(losses))\n","epochs = losses.size\n","x_epochs = [i + 1 for i in range(epochs)]\n","fig = plt.figure()\n","ax = fig.add_subplot(111)\n","ax.plot(x_epochs,losses, color = 'blue')\n","ax.yaxis.set_major_formatter(mtick.FormatStrFormatter('%.2e'))\n","plt.setp(ax, xlabel='Iteration')\n","plt.setp(ax, ylabel='Loss')\n","plt.show()\n","\n","a_file = open(\"Loss21.txt\", \"w\")\n","for row in np.array(model.lossHistogram).reshape(len(model.lossHistogram), 1):\n","    np.savetxt(a_file, row)\n","a_file.close()"],"execution_count":72,"outputs":[{"output_type":"stream","text":["Device mapping:\n","/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n","\n","Loss: 3.917e+02\n","Loss: 3.486e+02\n","Loss: 2.646e+02\n","Loss: 9.927e+02\n","Loss: 2.296e+02\n","Loss: 1.636e+03\n","Loss: 2.407e+02\n","Loss: 2.133e+02\n","Loss: 2.143e+02\n","Loss: 2.062e+02\n","Loss: 2.002e+02\n","Loss: 1.814e+02\n","Loss: 1.352e+02\n","Loss: 1.035e+02\n","Loss: 9.057e+01\n","Loss: 1.270e+02\n","Loss: 8.396e+01\n","Loss: 7.931e+01\n","Loss: 7.209e+01\n","Loss: 7.634e+01\n","Loss: 6.446e+01\n","Loss: 5.772e+01\n","Loss: 5.152e+01\n","Loss: 4.317e+01\n","Loss: 4.401e+01\n","Loss: 3.739e+01\n","Loss: 3.529e+01\n","Loss: 3.260e+01\n","Loss: 3.004e+01\n","Loss: 2.739e+01\n","Loss: 2.634e+01\n","Loss: 2.459e+01\n","Loss: 1.905e+01\n","Loss: 1.596e+01\n","Loss: 1.376e+01\n","Loss: 1.215e+01\n","Loss: 1.062e+01\n","Loss: 8.860e+00\n","Loss: 6.878e+00\n","Loss: 5.466e+00\n","Loss: 4.767e+00\n","Loss: 4.232e+00\n","Loss: 3.916e+00\n","Loss: 3.478e+00\n","Loss: 2.978e+00\n","Loss: 2.624e+00\n","Loss: 2.437e+00\n","Loss: 2.355e+00\n","Loss: 2.309e+00\n","Loss: 2.227e+00\n","Loss: 2.140e+00\n","Loss: 2.042e+00\n","Loss: 1.959e+00\n","Loss: 1.888e+00\n","Loss: 1.786e+00\n","Loss: 1.651e+00\n","Loss: 1.564e+00\n","Loss: 1.508e+00\n","Loss: 1.428e+00\n","Loss: 1.347e+00\n","Loss: 1.276e+00\n","Loss: 1.235e+00\n","Loss: 1.194e+00\n","Loss: 1.170e+00\n","Loss: 1.155e+00\n","Loss: 1.137e+00\n","Loss: 1.114e+00\n","Loss: 1.071e+00\n","Loss: 1.030e+00\n","Loss: 1.002e+00\n","Loss: 9.585e-01\n","Loss: 8.958e-01\n","Loss: 8.374e-01\n","Loss: 7.846e-01\n","Loss: 7.481e-01\n","Loss: 7.325e-01\n","Loss: 7.112e-01\n","Loss: 6.869e-01\n","Loss: 6.478e-01\n","Loss: 6.378e-01\n","Loss: 6.318e-01\n","Loss: 6.257e-01\n","Loss: 6.159e-01\n","Loss: 5.997e-01\n","Loss: 5.794e-01\n","Loss: 5.504e-01\n","Loss: 5.250e-01\n","Loss: 5.086e-01\n","Loss: 5.003e-01\n","Loss: 4.957e-01\n","Loss: 4.921e-01\n","Loss: 4.880e-01\n","Loss: 4.800e-01\n","Loss: 4.695e-01\n","Loss: 4.574e-01\n","Loss: 4.563e-01\n","Loss: 4.467e-01\n","Loss: 4.369e-01\n","Loss: 4.287e-01\n","Loss: 4.230e-01\n","Loss: 4.186e-01\n","Loss: 4.148e-01\n","Loss: 4.113e-01\n","Loss: 4.064e-01\n","Loss: 3.991e-01\n","Loss: 3.941e-01\n","Loss: 3.908e-01\n","Loss: 3.891e-01\n","Loss: 3.847e-01\n","Loss: 3.722e-01\n","Loss: 3.516e-01\n","Loss: 3.339e-01\n","Loss: 3.237e-01\n","Loss: 3.218e-01\n","Loss: 3.171e-01\n","Loss: 3.153e-01\n","Loss: 3.119e-01\n","Loss: 3.086e-01\n","Loss: 3.025e-01\n","Loss: 2.964e-01\n","Loss: 2.919e-01\n","Loss: 2.886e-01\n","Loss: 2.859e-01\n","Loss: 2.827e-01\n","Loss: 2.810e-01\n","Loss: 2.781e-01\n","Loss: 2.750e-01\n","Loss: 2.738e-01\n","Loss: 2.651e-01\n","Loss: 2.597e-01\n","Loss: 2.500e-01\n","Loss: 2.452e-01\n","Loss: 2.434e-01\n","Loss: 2.414e-01\n","Loss: 2.401e-01\n","Loss: 2.382e-01\n","Loss: 2.340e-01\n","Loss: 2.295e-01\n","Loss: 2.214e-01\n","Loss: 2.141e-01\n","Loss: 2.117e-01\n","Loss: 2.088e-01\n","Loss: 2.086e-01\n","Loss: 2.076e-01\n","Loss: 2.072e-01\n","Loss: 2.068e-01\n","Loss: 2.060e-01\n","Loss: 2.051e-01\n","Loss: 2.026e-01\n","Loss: 1.994e-01\n","Loss: 1.951e-01\n","Loss: 1.912e-01\n","Loss: 1.892e-01\n","Loss: 1.874e-01\n","Loss: 1.843e-01\n","Loss: 1.810e-01\n","Loss: 1.779e-01\n","Loss: 1.748e-01\n","Loss: 1.705e-01\n","Loss: 1.700e-01\n","Loss: 1.675e-01\n","Loss: 1.608e-01\n","Loss: 1.525e-01\n","Loss: 1.499e-01\n","Loss: 1.573e-01\n","Loss: 1.468e-01\n","Loss: 1.479e-01\n","Loss: 1.454e-01\n","Loss: 1.443e-01\n","Loss: 1.428e-01\n","Loss: 1.400e-01\n","Loss: 1.373e-01\n","Loss: 1.351e-01\n","Loss: 1.333e-01\n","Loss: 1.311e-01\n","Loss: 1.301e-01\n","Loss: 1.285e-01\n","Loss: 1.263e-01\n","Loss: 1.238e-01\n","Loss: 1.197e-01\n","Loss: 1.163e-01\n","Loss: 1.119e-01\n","Loss: 1.159e-01\n","Loss: 1.103e-01\n","Loss: 1.077e-01\n","Loss: 1.052e-01\n","Loss: 1.021e-01\n","Loss: 9.965e-02\n","Loss: 9.773e-02\n","Loss: 9.633e-02\n","Loss: 9.518e-02\n","Loss: 9.430e-02\n","Loss: 9.368e-02\n","Loss: 9.305e-02\n","Loss: 9.207e-02\n","Loss: 9.049e-02\n","Loss: 8.773e-02\n","Loss: 8.497e-02\n","Loss: 8.451e-02\n","Loss: 8.385e-02\n","Loss: 8.250e-02\n","Loss: 8.170e-02\n","Loss: 8.075e-02\n","Loss: 8.040e-02\n","Loss: 8.008e-02\n","Loss: 7.957e-02\n","Loss: 7.863e-02\n","Loss: 7.630e-02\n","Loss: 7.451e-02\n","Loss: 7.222e-02\n","Loss: 7.094e-02\n","Loss: 7.017e-02\n","Loss: 6.941e-02\n","Loss: 6.824e-02\n","Loss: 6.738e-02\n","Loss: 6.697e-02\n","Loss: 6.655e-02\n","Loss: 6.611e-02\n","Loss: 6.569e-02\n","Loss: 6.517e-02\n","Loss: 6.435e-02\n","Loss: 6.427e-02\n","Loss: 6.389e-02\n","Loss: 6.303e-02\n","Loss: 6.262e-02\n","Loss: 6.235e-02\n","Loss: 6.219e-02\n","Loss: 6.196e-02\n","Loss: 6.176e-02\n","Loss: 6.145e-02\n","Loss: 6.098e-02\n","Loss: 6.022e-02\n","Loss: 5.939e-02\n","Loss: 5.892e-02\n","Loss: 5.870e-02\n","Loss: 5.848e-02\n","Loss: 5.826e-02\n","Loss: 5.785e-02\n","Loss: 5.767e-02\n","Loss: 5.747e-02\n","Loss: 5.729e-02\n","Loss: 5.705e-02\n","Loss: 5.667e-02\n","Loss: 5.616e-02\n","Loss: 5.728e-02\n","Loss: 5.583e-02\n","Loss: 5.523e-02\n","Loss: 5.469e-02\n","Loss: 5.424e-02\n","Loss: 5.381e-02\n","Loss: 5.349e-02\n","Loss: 5.330e-02\n","Loss: 5.285e-02\n","Loss: 5.266e-02\n","Loss: 5.248e-02\n","Loss: 5.228e-02\n","Loss: 5.199e-02\n","Loss: 5.168e-02\n","Loss: 5.120e-02\n","Loss: 5.050e-02\n","Loss: 4.995e-02\n","Loss: 4.935e-02\n","Loss: 4.902e-02\n","Loss: 4.858e-02\n","Loss: 4.829e-02\n","Loss: 4.795e-02\n","Loss: 4.762e-02\n","Loss: 4.740e-02\n","Loss: 4.729e-02\n","Loss: 4.720e-02\n","Loss: 4.701e-02\n","Loss: 4.674e-02\n","Loss: 4.853e-02\n","Loss: 4.663e-02\n","Loss: 4.644e-02\n","Loss: 4.616e-02\n","Loss: 4.605e-02\n","Loss: 4.584e-02\n","Loss: 4.559e-02\n","Loss: 4.512e-02\n","Loss: 4.473e-02\n","Loss: 4.426e-02\n","Loss: 4.394e-02\n","Loss: 4.365e-02\n","Loss: 4.338e-02\n","Loss: 4.318e-02\n","Loss: 4.305e-02\n","Loss: 4.296e-02\n","Loss: 4.285e-02\n","Loss: 4.281e-02\n","Loss: 4.259e-02\n","Loss: 4.252e-02\n","Loss: 4.241e-02\n","Loss: 4.227e-02\n","Loss: 4.209e-02\n","Loss: 4.190e-02\n","Loss: 4.169e-02\n","Loss: 4.142e-02\n","Loss: 4.121e-02\n","Loss: 4.093e-02\n","Loss: 4.072e-02\n","Loss: 4.061e-02\n","Loss: 4.046e-02\n","Loss: 4.034e-02\n","Loss: 4.023e-02\n","Loss: 4.014e-02\n","Loss: 3.998e-02\n","Loss: 3.991e-02\n","Loss: 3.984e-02\n","Loss: 3.973e-02\n","Loss: 3.968e-02\n","Loss: 3.954e-02\n","Loss: 3.945e-02\n","Loss: 3.930e-02\n","Loss: 3.912e-02\n","Loss: 3.934e-02\n","Loss: 3.903e-02\n","Loss: 3.867e-02\n","Loss: 3.837e-02\n","Loss: 3.785e-02\n","Loss: 3.755e-02\n","Loss: 3.867e-02\n","Loss: 3.733e-02\n","Loss: 3.718e-02\n","Loss: 3.696e-02\n","Loss: 3.686e-02\n","Loss: 3.675e-02\n","Loss: 3.667e-02\n","Loss: 3.660e-02\n","Loss: 3.651e-02\n","Loss: 3.641e-02\n","Loss: 3.627e-02\n","Loss: 3.610e-02\n","Loss: 3.588e-02\n","Loss: 3.571e-02\n","Loss: 3.546e-02\n","Loss: 3.525e-02\n","Loss: 3.498e-02\n","Loss: 3.472e-02\n","Loss: 3.455e-02\n","Loss: 3.443e-02\n","Loss: 3.425e-02\n","Loss: 3.402e-02\n","Loss: 3.391e-02\n","Loss: 3.373e-02\n","Loss: 3.338e-02\n","Loss: 3.323e-02\n","Loss: 3.309e-02\n","Loss: 3.295e-02\n","Loss: 3.291e-02\n","Loss: 3.286e-02\n","Loss: 3.283e-02\n","Loss: 3.280e-02\n","Loss: 3.278e-02\n","Loss: 3.272e-02\n","Loss: 3.267e-02\n","Loss: 3.261e-02\n","Loss: 3.257e-02\n","Loss: 3.253e-02\n","Loss: 3.249e-02\n","Loss: 3.243e-02\n","Loss: 3.240e-02\n","Loss: 3.234e-02\n","Loss: 3.225e-02\n","Loss: 3.214e-02\n","Loss: 3.206e-02\n","Loss: 3.192e-02\n","Loss: 3.185e-02\n","Loss: 3.178e-02\n","Loss: 3.164e-02\n","Loss: 3.149e-02\n","Loss: 3.139e-02\n","Loss: 3.130e-02\n","Loss: 3.119e-02\n","Loss: 3.143e-02\n","Loss: 3.113e-02\n","Loss: 3.100e-02\n","Loss: 3.087e-02\n","Loss: 3.079e-02\n","Loss: 3.063e-02\n","Loss: 3.045e-02\n","Loss: 3.031e-02\n","Loss: 3.015e-02\n","Loss: 2.999e-02\n","Loss: 2.984e-02\n","Loss: 2.970e-02\n","Loss: 2.957e-02\n","Loss: 2.947e-02\n","Loss: 2.932e-02\n","Loss: 2.909e-02\n","Loss: 2.885e-02\n","Loss: 2.868e-02\n","Loss: 2.848e-02\n","Loss: 2.828e-02\n","Loss: 2.813e-02\n","Loss: 2.800e-02\n","Loss: 2.787e-02\n","Loss: 2.771e-02\n","Loss: 2.763e-02\n","Loss: 2.755e-02\n","Loss: 2.746e-02\n","Loss: 2.734e-02\n","Loss: 2.720e-02\n","Loss: 2.704e-02\n","Loss: 2.685e-02\n","Loss: 2.671e-02\n","Loss: 2.658e-02\n","Loss: 2.638e-02\n","Loss: 2.628e-02\n","Loss: 2.588e-02\n","Loss: 2.575e-02\n","Loss: 2.564e-02\n","Loss: 2.552e-02\n","Loss: 2.543e-02\n","Loss: 2.538e-02\n","Loss: 2.532e-02\n","Loss: 2.526e-02\n","Loss: 2.515e-02\n","Loss: 2.502e-02\n","Loss: 2.486e-02\n","Loss: 2.475e-02\n","Loss: 2.468e-02\n","Loss: 2.458e-02\n","Loss: 2.447e-02\n","Loss: 2.433e-02\n","Loss: 2.418e-02\n","Loss: 2.427e-02\n","Loss: 2.409e-02\n","Loss: 2.392e-02\n","Loss: 2.383e-02\n","Loss: 2.373e-02\n","Loss: 2.368e-02\n","Loss: 2.365e-02\n","Loss: 2.362e-02\n","Loss: 2.357e-02\n","Loss: 2.344e-02\n","Loss: 2.334e-02\n","Loss: 2.323e-02\n","Loss: 2.319e-02\n","Loss: 2.307e-02\n","Loss: 2.299e-02\n","Loss: 2.287e-02\n","Loss: 2.268e-02\n","Loss: 2.246e-02\n","Loss: 2.236e-02\n","Loss: 2.230e-02\n","Loss: 2.225e-02\n","Loss: 2.220e-02\n","Loss: 2.213e-02\n","Loss: 2.203e-02\n","Loss: 2.195e-02\n","Loss: 2.187e-02\n","Loss: 2.181e-02\n","Loss: 2.165e-02\n","Loss: 2.156e-02\n","Loss: 2.272e-02\n","Loss: 2.152e-02\n","Loss: 2.146e-02\n","Loss: 2.141e-02\n","Loss: 2.134e-02\n","Loss: 2.119e-02\n","Loss: 2.106e-02\n","Loss: 2.097e-02\n","Loss: 2.088e-02\n","Loss: 2.080e-02\n","Loss: 2.073e-02\n","Loss: 2.064e-02\n","Loss: 2.070e-02\n","Loss: 2.059e-02\n","Loss: 2.049e-02\n","Loss: 2.043e-02\n","Loss: 2.036e-02\n","Loss: 2.031e-02\n","Loss: 2.026e-02\n","Loss: 2.018e-02\n","Loss: 2.004e-02\n","Loss: 1.994e-02\n","Loss: 2.023e-02\n","Loss: 1.984e-02\n","Loss: 1.973e-02\n","Loss: 1.965e-02\n","Loss: 1.961e-02\n","Loss: 1.957e-02\n","Loss: 1.953e-02\n","Loss: 1.948e-02\n","Loss: 1.942e-02\n","Loss: 1.936e-02\n","Loss: 1.932e-02\n","Loss: 1.930e-02\n","Loss: 1.927e-02\n","Loss: 1.925e-02\n","Loss: 1.923e-02\n","Loss: 1.920e-02\n","Loss: 1.916e-02\n","Loss: 1.913e-02\n","Loss: 1.925e-02\n","Loss: 1.910e-02\n","Loss: 1.903e-02\n","Loss: 1.884e-02\n","Loss: 1.869e-02\n","Loss: 1.853e-02\n","Loss: 1.843e-02\n","Loss: 1.837e-02\n","Loss: 1.834e-02\n","Loss: 1.831e-02\n","Loss: 1.827e-02\n","Loss: 1.823e-02\n","Loss: 1.818e-02\n","Loss: 1.813e-02\n","Loss: 1.808e-02\n","Loss: 1.801e-02\n","Loss: 1.791e-02\n","Loss: 1.780e-02\n","Loss: 1.772e-02\n","Loss: 1.764e-02\n","Loss: 1.759e-02\n","Loss: 1.753e-02\n","Loss: 1.746e-02\n","Loss: 1.740e-02\n","Loss: 1.739e-02\n","Loss: 1.731e-02\n","Loss: 1.728e-02\n","Loss: 1.726e-02\n","Loss: 1.722e-02\n","Loss: 1.721e-02\n","Loss: 1.714e-02\n","Loss: 1.710e-02\n","Loss: 1.708e-02\n","Loss: 1.704e-02\n","Loss: 1.702e-02\n","Loss: 1.701e-02\n","Loss: 1.699e-02\n","Loss: 1.696e-02\n","Loss: 1.693e-02\n","Loss: 1.689e-02\n","Loss: 1.684e-02\n","Loss: 1.678e-02\n","Loss: 1.668e-02\n","Loss: 1.663e-02\n","Loss: 1.656e-02\n","Loss: 1.652e-02\n","Loss: 1.648e-02\n","Loss: 1.644e-02\n","Loss: 1.639e-02\n","Loss: 1.631e-02\n","Loss: 1.622e-02\n","Loss: 1.613e-02\n","Loss: 1.605e-02\n","Loss: 1.592e-02\n","Loss: 1.582e-02\n","Loss: 1.571e-02\n","Loss: 1.571e-02\n","Loss: 1.566e-02\n","Loss: 1.555e-02\n","Loss: 1.548e-02\n","Loss: 1.541e-02\n","Loss: 1.534e-02\n","Loss: 1.525e-02\n","Loss: 1.517e-02\n","Loss: 1.512e-02\n","Loss: 1.507e-02\n","Loss: 1.503e-02\n","Loss: 1.500e-02\n","Loss: 1.493e-02\n","Loss: 1.489e-02\n","Loss: 1.485e-02\n","Loss: 1.482e-02\n","Loss: 1.479e-02\n","Loss: 1.471e-02\n","Loss: 1.473e-02\n","Loss: 1.467e-02\n","Loss: 1.459e-02\n","Loss: 1.451e-02\n","Loss: 1.449e-02\n","Loss: 1.445e-02\n","Loss: 1.439e-02\n","Loss: 1.435e-02\n","Loss: 1.431e-02\n","Loss: 1.427e-02\n","Loss: 1.422e-02\n","Loss: 1.417e-02\n","Loss: 1.411e-02\n","Loss: 1.405e-02\n","Loss: 1.400e-02\n","Loss: 1.394e-02\n","Loss: 1.391e-02\n","Loss: 1.383e-02\n","Loss: 1.379e-02\n","Loss: 1.372e-02\n","Loss: 1.368e-02\n","Loss: 1.364e-02\n","Loss: 1.362e-02\n","Loss: 1.361e-02\n","Loss: 1.359e-02\n","Loss: 1.358e-02\n","Loss: 1.356e-02\n","Loss: 1.355e-02\n","Loss: 1.353e-02\n","Loss: 1.351e-02\n","Loss: 1.347e-02\n","Loss: 1.340e-02\n","Loss: 1.335e-02\n","Loss: 1.327e-02\n","Loss: 1.320e-02\n","Loss: 1.316e-02\n","Loss: 1.314e-02\n","Loss: 1.312e-02\n","Loss: 1.307e-02\n","Loss: 1.301e-02\n","Loss: 1.309e-02\n","Loss: 1.298e-02\n","Loss: 1.293e-02\n","Loss: 1.288e-02\n","Loss: 1.284e-02\n","Loss: 1.280e-02\n","Loss: 1.276e-02\n","Loss: 1.273e-02\n","Loss: 1.271e-02\n","Loss: 1.268e-02\n","Loss: 1.263e-02\n","Loss: 1.258e-02\n","Loss: 1.250e-02\n","Loss: 1.243e-02\n","Loss: 1.237e-02\n","Loss: 1.231e-02\n","Loss: 1.225e-02\n","Loss: 1.220e-02\n","Loss: 1.214e-02\n","Loss: 1.207e-02\n","Loss: 1.204e-02\n","Loss: 1.204e-02\n","Loss: 1.202e-02\n","Loss: 1.197e-02\n","Loss: 1.189e-02\n","Loss: 1.210e-02\n","Loss: 1.187e-02\n","Loss: 1.182e-02\n","Loss: 1.178e-02\n","Loss: 1.174e-02\n","Loss: 1.171e-02\n","Loss: 1.166e-02\n","Loss: 1.163e-02\n","Loss: 1.161e-02\n","Loss: 1.160e-02\n","Loss: 1.160e-02\n","Loss: 1.159e-02\n","Loss: 1.156e-02\n","Loss: 1.154e-02\n","Loss: 1.152e-02\n","Loss: 1.149e-02\n","Loss: 1.147e-02\n","Loss: 1.143e-02\n","Loss: 1.140e-02\n","Loss: 1.136e-02\n","Loss: 1.132e-02\n","Loss: 1.128e-02\n","Loss: 1.124e-02\n","Loss: 1.121e-02\n","Loss: 1.121e-02\n","Loss: 1.119e-02\n","Loss: 1.116e-02\n","Loss: 1.115e-02\n","Loss: 1.112e-02\n","Loss: 1.109e-02\n","Loss: 1.105e-02\n","Loss: 1.098e-02\n","Loss: 1.093e-02\n","Loss: 1.106e-02\n","Loss: 1.091e-02\n","Loss: 1.088e-02\n","Loss: 1.085e-02\n","Loss: 1.083e-02\n","Loss: 1.080e-02\n","Loss: 1.077e-02\n","Loss: 1.075e-02\n","Loss: 1.072e-02\n","Loss: 1.069e-02\n","Loss: 1.064e-02\n","Loss: 1.058e-02\n","Loss: 1.048e-02\n","Loss: 1.043e-02\n","Loss: 1.039e-02\n","Loss: 1.069e-02\n","Loss: 1.035e-02\n","Loss: 1.027e-02\n","Loss: 1.023e-02\n","Loss: 1.019e-02\n","Loss: 1.013e-02\n","Loss: 1.008e-02\n","Loss: 1.003e-02\n","Loss: 1.002e-02\n","Loss: 9.990e-03\n","Loss: 9.970e-03\n","Loss: 9.956e-03\n","Loss: 9.940e-03\n","Loss: 9.932e-03\n","Loss: 9.924e-03\n","Loss: 9.905e-03\n","Loss: 9.929e-03\n","Loss: 9.890e-03\n","Loss: 9.852e-03\n","Loss: 9.816e-03\n","Loss: 9.752e-03\n","Loss: 9.677e-03\n","Loss: 9.544e-03\n","Loss: 1.428e-02\n","Loss: 9.511e-03\n","Loss: 9.366e-03\n","Loss: 9.151e-03\n","Loss: 9.032e-03\n","Loss: 8.976e-03\n","Loss: 8.945e-03\n","Loss: 8.932e-03\n","Loss: 8.871e-03\n","Loss: 8.857e-03\n","Loss: 8.837e-03\n","Loss: 8.825e-03\n","Loss: 8.812e-03\n","Loss: 8.808e-03\n","Loss: 8.802e-03\n","Loss: 8.798e-03\n","Loss: 8.789e-03\n","Loss: 8.771e-03\n","Loss: 8.746e-03\n","Loss: 8.729e-03\n","Loss: 8.695e-03\n","Loss: 8.678e-03\n","Loss: 8.651e-03\n","Loss: 8.628e-03\n","Loss: 8.593e-03\n","Loss: 8.566e-03\n","Loss: 8.542e-03\n","Loss: 8.531e-03\n","Loss: 8.492e-03\n","Loss: 8.452e-03\n","Loss: 8.410e-03\n","Loss: 8.374e-03\n","Loss: 8.363e-03\n","Loss: 8.312e-03\n","Loss: 8.290e-03\n","Loss: 8.258e-03\n","Loss: 8.246e-03\n","Loss: 8.221e-03\n","Loss: 8.211e-03\n","Loss: 8.195e-03\n","Loss: 8.181e-03\n","Loss: 8.165e-03\n","Loss: 8.148e-03\n","Loss: 8.126e-03\n","Loss: 8.122e-03\n","Loss: 8.102e-03\n","Loss: 8.096e-03\n","Loss: 8.089e-03\n","Loss: 8.083e-03\n","Loss: 8.075e-03\n","Loss: 8.070e-03\n","Loss: 8.062e-03\n","Loss: 8.054e-03\n","Loss: 8.051e-03\n","Loss: 8.037e-03\n","Loss: 8.030e-03\n","Loss: 8.024e-03\n","Loss: 8.022e-03\n","Loss: 8.012e-03\n","Loss: 8.009e-03\n","Loss: 7.997e-03\n","Loss: 7.983e-03\n","Loss: 7.974e-03\n","Loss: 7.948e-03\n","Loss: 7.934e-03\n","Loss: 7.918e-03\n","Loss: 7.906e-03\n","Loss: 7.887e-03\n","Loss: 7.859e-03\n","Loss: 7.841e-03\n","Loss: 7.828e-03\n","Loss: 7.818e-03\n","Loss: 7.804e-03\n","Loss: 7.790e-03\n","Loss: 7.766e-03\n","Loss: 7.743e-03\n","Loss: 7.721e-03\n","Loss: 7.685e-03\n","Loss: 7.662e-03\n","Loss: 7.641e-03\n","Loss: 7.615e-03\n","Loss: 7.582e-03\n","Loss: 7.551e-03\n","Loss: 7.523e-03\n","Loss: 7.507e-03\n","Loss: 7.477e-03\n","Loss: 7.436e-03\n","Loss: 7.411e-03\n","Loss: 7.378e-03\n","Loss: 7.327e-03\n","Loss: 7.302e-03\n","Loss: 7.257e-03\n","Loss: 7.238e-03\n","Loss: 7.222e-03\n","Loss: 7.202e-03\n","Loss: 7.169e-03\n","Loss: 7.138e-03\n","Loss: 7.111e-03\n","Loss: 7.086e-03\n","Loss: 7.061e-03\n","Loss: 7.029e-03\n","Loss: 6.996e-03\n","Loss: 6.955e-03\n","Loss: 6.925e-03\n","Loss: 6.867e-03\n","Loss: 6.824e-03\n","Loss: 6.791e-03\n","Loss: 6.737e-03\n","Loss: 6.707e-03\n","Loss: 6.678e-03\n","Loss: 6.648e-03\n","Loss: 6.616e-03\n","Loss: 6.590e-03\n","Loss: 6.545e-03\n","Loss: 6.533e-03\n","Loss: 6.498e-03\n","Loss: 6.453e-03\n","Loss: 6.437e-03\n","Loss: 6.422e-03\n","Loss: 6.390e-03\n","Loss: 6.362e-03\n","Loss: 6.366e-03\n","Loss: 6.333e-03\n","Loss: 6.306e-03\n","Loss: 6.275e-03\n","Loss: 6.250e-03\n","Loss: 6.211e-03\n","Loss: 6.488e-03\n","Loss: 6.192e-03\n","Loss: 6.159e-03\n","Loss: 6.147e-03\n","Loss: 6.131e-03\n","Loss: 6.115e-03\n","Loss: 6.095e-03\n","Loss: 6.078e-03\n","Loss: 6.065e-03\n","Loss: 6.048e-03\n","Loss: 6.032e-03\n","Loss: 6.015e-03\n","Loss: 5.999e-03\n","Loss: 5.993e-03\n","Loss: 5.986e-03\n","Loss: 5.978e-03\n","Loss: 5.972e-03\n","Loss: 5.960e-03\n","Loss: 5.950e-03\n","Loss: 6.015e-03\n","Loss: 5.939e-03\n","Loss: 5.934e-03\n","Loss: 5.917e-03\n","Loss: 5.907e-03\n","Loss: 5.892e-03\n","Loss: 5.879e-03\n","Loss: 5.863e-03\n","Loss: 5.848e-03\n","Loss: 5.833e-03\n","Loss: 5.811e-03\n","Loss: 5.791e-03\n","Loss: 5.766e-03\n","Loss: 5.744e-03\n","Loss: 5.722e-03\n","Loss: 5.702e-03\n","Loss: 5.684e-03\n","Loss: 5.660e-03\n","Loss: 5.633e-03\n","Loss: 5.612e-03\n","Loss: 5.586e-03\n","Loss: 5.560e-03\n","Loss: 5.541e-03\n","Loss: 5.524e-03\n","Loss: 5.506e-03\n","Loss: 5.512e-03\n","Loss: 5.496e-03\n","Loss: 5.489e-03\n","Loss: 5.480e-03\n","Loss: 5.467e-03\n","Loss: 5.437e-03\n","Loss: 5.417e-03\n","Loss: 5.420e-03\n","Loss: 5.403e-03\n","Loss: 5.385e-03\n","Loss: 5.441e-03\n","Loss: 5.373e-03\n","Loss: 5.350e-03\n","Loss: 5.309e-03\n","Loss: 5.293e-03\n","Loss: 5.274e-03\n","Loss: 5.265e-03\n","Loss: 5.251e-03\n","Loss: 5.237e-03\n","Loss: 5.215e-03\n","Loss: 5.200e-03\n","Loss: 5.179e-03\n","Loss: 5.165e-03\n","Loss: 5.149e-03\n","Loss: 5.137e-03\n","Loss: 5.123e-03\n","Loss: 5.111e-03\n","Loss: 5.096e-03\n","Loss: 5.090e-03\n","Loss: 5.069e-03\n","Loss: 5.055e-03\n","Loss: 5.040e-03\n","Loss: 5.017e-03\n","Loss: 5.000e-03\n","Loss: 4.981e-03\n","Loss: 4.964e-03\n","Loss: 4.946e-03\n","Loss: 5.020e-03\n","Loss: 4.938e-03\n","Loss: 4.915e-03\n","Loss: 4.888e-03\n","Loss: 4.869e-03\n","Loss: 4.853e-03\n","Loss: 4.839e-03\n","Loss: 4.819e-03\n","Loss: 4.796e-03\n","Loss: 4.774e-03\n","Loss: 4.744e-03\n","Loss: 4.782e-03\n","Loss: 4.733e-03\n","Loss: 4.716e-03\n","Loss: 4.701e-03\n","Loss: 4.691e-03\n","Loss: 4.676e-03\n","Loss: 4.649e-03\n","Loss: 4.648e-03\n","Loss: 4.627e-03\n","Loss: 4.610e-03\n","Loss: 4.598e-03\n","Loss: 4.589e-03\n","Loss: 4.571e-03\n","Loss: 4.555e-03\n","Loss: 4.542e-03\n","Loss: 4.534e-03\n","Loss: 4.526e-03\n","Loss: 4.516e-03\n","Loss: 4.508e-03\n","Loss: 4.491e-03\n","Loss: 4.480e-03\n","Loss: 4.460e-03\n","Loss: 4.448e-03\n","Loss: 4.428e-03\n","Loss: 4.411e-03\n","Loss: 4.401e-03\n","Loss: 4.390e-03\n","Loss: 4.378e-03\n","Loss: 4.370e-03\n","Loss: 4.357e-03\n","Loss: 4.335e-03\n","Loss: 4.311e-03\n","Loss: 4.289e-03\n","Loss: 4.274e-03\n","Loss: 4.260e-03\n","Loss: 4.240e-03\n","Loss: 4.198e-03\n","Loss: 4.176e-03\n","Loss: 4.148e-03\n","Loss: 4.129e-03\n","Loss: 4.107e-03\n","Loss: 4.085e-03\n","Loss: 4.067e-03\n","Loss: 4.056e-03\n","Loss: 4.043e-03\n","Loss: 4.028e-03\n","Loss: 4.035e-03\n","Loss: 4.021e-03\n","Loss: 4.008e-03\n","Loss: 3.997e-03\n","Loss: 3.989e-03\n","Loss: 3.978e-03\n","Loss: 3.966e-03\n","Loss: 3.959e-03\n","Loss: 3.954e-03\n","Loss: 3.947e-03\n","Loss: 3.937e-03\n","Loss: 3.966e-03\n","Loss: 3.934e-03\n","Loss: 3.926e-03\n","Loss: 3.914e-03\n","Loss: 3.899e-03\n","Loss: 3.886e-03\n","Loss: 3.881e-03\n","Loss: 3.870e-03\n","Loss: 3.863e-03\n","Loss: 3.857e-03\n","Loss: 3.848e-03\n","Loss: 3.839e-03\n","Loss: 3.821e-03\n","Loss: 3.807e-03\n","Loss: 3.789e-03\n","Loss: 3.775e-03\n","Loss: 3.759e-03\n","Loss: 3.750e-03\n","Loss: 3.740e-03\n","Loss: 3.735e-03\n","Loss: 3.727e-03\n","Loss: 3.718e-03\n","Loss: 3.707e-03\n","Loss: 3.696e-03\n","Loss: 3.690e-03\n","Loss: 3.677e-03\n","Loss: 3.667e-03\n","Loss: 3.653e-03\n","Loss: 3.763e-03\n","Loss: 3.648e-03\n","Loss: 3.640e-03\n","Loss: 3.631e-03\n","Loss: 3.626e-03\n","Loss: 3.620e-03\n","Loss: 3.611e-03\n","Loss: 3.605e-03\n","Loss: 3.591e-03\n","Loss: 3.577e-03\n","Loss: 3.565e-03\n","Loss: 3.554e-03\n","Loss: 3.544e-03\n","Loss: 3.520e-03\n","Loss: 3.500e-03\n","Loss: 3.483e-03\n","Loss: 3.468e-03\n","Loss: 3.459e-03\n","Loss: 3.448e-03\n","Loss: 3.436e-03\n","Loss: 3.423e-03\n","Loss: 3.415e-03\n","Loss: 3.405e-03\n","Loss: 3.393e-03\n","Loss: 3.382e-03\n","Loss: 3.367e-03\n","Loss: 3.354e-03\n","Loss: 3.342e-03\n","Loss: 3.329e-03\n","Loss: 3.310e-03\n","Loss: 3.300e-03\n","Loss: 3.289e-03\n","Loss: 3.275e-03\n","Loss: 3.262e-03\n","Loss: 3.251e-03\n","Loss: 3.236e-03\n","Loss: 3.227e-03\n","Loss: 3.216e-03\n","Loss: 3.502e-03\n","Loss: 3.213e-03\n","Loss: 3.205e-03\n","Loss: 3.198e-03\n","Loss: 3.188e-03\n","Loss: 3.175e-03\n","Loss: 3.163e-03\n","Loss: 3.153e-03\n","Loss: 3.143e-03\n","Loss: 3.130e-03\n","Loss: 3.115e-03\n","Loss: 3.098e-03\n","Loss: 3.085e-03\n","Loss: 3.073e-03\n","Loss: 3.059e-03\n","Loss: 3.046e-03\n","Loss: 3.020e-03\n","Loss: 3.008e-03\n","Loss: 2.990e-03\n","Loss: 2.989e-03\n","Loss: 2.983e-03\n","Loss: 2.973e-03\n","Loss: 2.962e-03\n","Loss: 2.956e-03\n","Loss: 2.948e-03\n","Loss: 2.938e-03\n","Loss: 2.922e-03\n","Loss: 2.907e-03\n","Loss: 2.895e-03\n","Loss: 2.883e-03\n","Loss: 2.874e-03\n","Loss: 2.860e-03\n","Loss: 2.848e-03\n","Loss: 2.842e-03\n","Loss: 2.835e-03\n","Loss: 2.828e-03\n","Loss: 2.821e-03\n","Loss: 2.815e-03\n","Loss: 2.807e-03\n","Loss: 2.796e-03\n","Loss: 2.786e-03\n","Loss: 2.781e-03\n","Loss: 2.773e-03\n","Loss: 2.768e-03\n","Loss: 2.762e-03\n","Loss: 2.757e-03\n","Loss: 2.753e-03\n","Loss: 2.750e-03\n","Loss: 2.747e-03\n","Loss: 2.740e-03\n","Loss: 2.918e-03\n","Loss: 2.737e-03\n","Loss: 2.727e-03\n","Loss: 2.713e-03\n","Loss: 2.705e-03\n","Loss: 2.697e-03\n","Loss: 2.789e-03\n","Loss: 2.688e-03\n","Loss: 2.671e-03\n","Loss: 2.658e-03\n","Loss: 2.650e-03\n","Loss: 2.644e-03\n","Loss: 2.638e-03\n","Loss: 2.632e-03\n","Loss: 2.624e-03\n","Loss: 2.616e-03\n","Loss: 2.611e-03\n","Loss: 2.608e-03\n","Loss: 2.602e-03\n","Loss: 2.593e-03\n","Loss: 2.576e-03\n","Loss: 2.580e-03\n","Loss: 2.565e-03\n","Loss: 2.554e-03\n","Loss: 2.542e-03\n","Loss: 2.537e-03\n","Loss: 2.531e-03\n","Loss: 2.526e-03\n","Loss: 2.523e-03\n","Loss: 2.519e-03\n","Loss: 2.513e-03\n","Loss: 2.504e-03\n","Loss: 2.492e-03\n","Loss: 2.481e-03\n","Loss: 2.471e-03\n","Loss: 2.461e-03\n","Loss: 2.454e-03\n","Loss: 2.449e-03\n","Loss: 2.444e-03\n","Loss: 2.440e-03\n","Loss: 2.435e-03\n","Loss: 2.430e-03\n","Loss: 2.424e-03\n","Loss: 2.419e-03\n","Loss: 2.414e-03\n","Loss: 2.409e-03\n","Loss: 2.402e-03\n","Loss: 2.394e-03\n","Loss: 2.386e-03\n","Loss: 2.378e-03\n","Loss: 2.371e-03\n","Loss: 2.372e-03\n","Loss: 2.368e-03\n","Loss: 2.363e-03\n","Loss: 2.358e-03\n","Loss: 2.351e-03\n","Loss: 2.344e-03\n","Loss: 2.337e-03\n","Loss: 2.379e-03\n","Loss: 2.336e-03\n","Loss: 2.334e-03\n","Loss: 2.332e-03\n","Loss: 2.328e-03\n","Loss: 2.321e-03\n","Loss: 2.314e-03\n","Loss: 2.313e-03\n","Loss: 2.309e-03\n","Loss: 2.303e-03\n","Loss: 2.300e-03\n","Loss: 2.296e-03\n","Loss: 2.294e-03\n","Loss: 2.291e-03\n","Loss: 2.288e-03\n","Loss: 2.285e-03\n","Loss: 2.280e-03\n","Loss: 2.272e-03\n","Loss: 2.263e-03\n","Loss: 2.255e-03\n","Loss: 2.252e-03\n","Loss: 2.249e-03\n","Loss: 2.247e-03\n","Loss: 2.244e-03\n","Loss: 2.249e-03\n","Loss: 2.242e-03\n","Loss: 2.238e-03\n","Loss: 2.236e-03\n","Loss: 2.233e-03\n","Loss: 2.238e-03\n","Loss: 2.231e-03\n","Loss: 2.227e-03\n","Loss: 2.220e-03\n","Loss: 2.214e-03\n","Loss: 2.205e-03\n","Loss: 2.198e-03\n","Loss: 2.189e-03\n","Loss: 2.183e-03\n","Loss: 2.182e-03\n","Loss: 2.173e-03\n","Loss: 2.167e-03\n","Loss: 2.158e-03\n","Loss: 2.151e-03\n","Loss: 2.145e-03\n","Loss: 2.144e-03\n","Loss: 2.137e-03\n","Loss: 2.135e-03\n","Loss: 2.132e-03\n","Loss: 2.129e-03\n","Loss: 2.126e-03\n","Loss: 2.122e-03\n","Loss: 2.117e-03\n","Loss: 2.111e-03\n","Loss: 2.104e-03\n","Loss: 2.098e-03\n","Loss: 2.093e-03\n","Loss: 2.102e-03\n","Loss: 2.090e-03\n","Loss: 2.087e-03\n","Loss: 2.083e-03\n","Loss: 2.079e-03\n","Loss: 2.071e-03\n","Loss: 2.064e-03\n","Loss: 2.061e-03\n","Loss: 2.058e-03\n","Loss: 2.056e-03\n","Loss: 2.054e-03\n","Loss: 2.051e-03\n","Loss: 2.049e-03\n","Loss: 2.050e-03\n","Loss: 2.047e-03\n","Loss: 2.044e-03\n","Loss: 2.042e-03\n","Loss: 2.041e-03\n","Loss: 2.038e-03\n","Loss: 2.033e-03\n","Loss: 2.030e-03\n","Loss: 2.026e-03\n","Loss: 2.024e-03\n","Loss: 2.021e-03\n","Loss: 2.019e-03\n","Loss: 2.016e-03\n","Loss: 2.014e-03\n","Loss: 2.012e-03\n","Loss: 2.017e-03\n","Loss: 2.010e-03\n","Loss: 2.008e-03\n","Loss: 2.006e-03\n","Loss: 2.005e-03\n","Loss: 2.004e-03\n","Loss: 2.003e-03\n","Loss: 2.002e-03\n","Loss: 2.001e-03\n","Loss: 2.000e-03\n","Loss: 1.997e-03\n","Loss: 2.003e-03\n","Loss: 1.996e-03\n","Loss: 1.993e-03\n","Loss: 1.991e-03\n","Loss: 1.990e-03\n","Loss: 1.988e-03\n","Loss: 1.983e-03\n","Loss: 1.983e-03\n","Loss: 1.979e-03\n","Loss: 1.978e-03\n","Loss: 1.976e-03\n","Loss: 1.978e-03\n","Loss: 1.975e-03\n","Loss: 1.973e-03\n","Loss: 1.971e-03\n","Loss: 1.968e-03\n","Loss: 1.964e-03\n","Loss: 1.959e-03\n","Loss: 1.955e-03\n","Loss: 1.950e-03\n","Loss: 1.948e-03\n","Loss: 1.946e-03\n","Loss: 1.946e-03\n","Loss: 1.944e-03\n","Loss: 1.941e-03\n","Loss: 1.938e-03\n","Loss: 1.936e-03\n","Loss: 1.933e-03\n","Loss: 1.943e-03\n","Loss: 1.931e-03\n","Loss: 1.926e-03\n","Loss: 1.921e-03\n","Loss: 1.945e-03\n","Loss: 1.920e-03\n","Loss: 1.917e-03\n","Loss: 1.917e-03\n","Loss: 1.913e-03\n","Loss: 1.911e-03\n","Loss: 1.908e-03\n","Loss: 1.904e-03\n","Loss: 1.902e-03\n","Loss: 1.898e-03\n","Loss: 1.895e-03\n","Loss: 1.893e-03\n","Loss: 1.890e-03\n","Loss: 1.899e-03\n","Loss: 1.888e-03\n","Loss: 1.885e-03\n","Loss: 1.882e-03\n","Loss: 1.879e-03\n","Loss: 1.877e-03\n","Loss: 1.875e-03\n","Loss: 1.871e-03\n","Loss: 1.867e-03\n","Loss: 1.864e-03\n","Loss: 1.860e-03\n","Loss: 1.855e-03\n","Loss: 1.849e-03\n","Loss: 1.844e-03\n","Loss: 1.850e-03\n","Loss: 1.842e-03\n","Loss: 1.840e-03\n","Loss: 1.838e-03\n","Loss: 1.835e-03\n","Loss: 1.833e-03\n","Loss: 1.832e-03\n","Loss: 1.830e-03\n","Loss: 1.829e-03\n","Loss: 1.828e-03\n","Loss: 1.827e-03\n","Loss: 1.825e-03\n","Loss: 1.823e-03\n","Loss: 1.820e-03\n","Loss: 1.818e-03\n","Loss: 1.816e-03\n","Loss: 1.813e-03\n","Loss: 1.813e-03\n","Loss: 1.810e-03\n","Loss: 1.806e-03\n","Loss: 1.799e-03\n","Loss: 1.795e-03\n","Loss: 1.792e-03\n","Loss: 1.788e-03\n","Loss: 1.787e-03\n","Loss: 1.785e-03\n","Loss: 1.783e-03\n","Loss: 1.782e-03\n","Loss: 1.781e-03\n","Loss: 1.779e-03\n","Loss: 1.778e-03\n","Loss: 1.777e-03\n","Loss: 1.776e-03\n","Loss: 1.774e-03\n","Loss: 1.772e-03\n","Loss: 1.770e-03\n","Loss: 1.774e-03\n","Loss: 1.770e-03\n","Loss: 1.769e-03\n","Loss: 1.768e-03\n","Loss: 1.766e-03\n","Loss: 1.764e-03\n","Loss: 1.761e-03\n","Loss: 1.758e-03\n","Loss: 1.753e-03\n","Loss: 1.749e-03\n","Loss: 1.743e-03\n","Loss: 1.736e-03\n","Loss: 1.737e-03\n","Loss: 1.733e-03\n","Loss: 1.728e-03\n","Loss: 1.726e-03\n","Loss: 1.725e-03\n","Loss: 1.723e-03\n","Loss: 1.722e-03\n","Loss: 1.720e-03\n","Loss: 1.719e-03\n","Loss: 1.718e-03\n","Loss: 1.717e-03\n","Loss: 1.716e-03\n","Loss: 1.714e-03\n","Loss: 1.713e-03\n","Loss: 1.711e-03\n","Loss: 1.709e-03\n","Loss: 1.707e-03\n","Loss: 1.705e-03\n","Loss: 1.701e-03\n","Loss: 1.698e-03\n","Loss: 1.694e-03\n","Loss: 1.690e-03\n","Loss: 1.686e-03\n","Loss: 1.682e-03\n","Loss: 1.683e-03\n","Loss: 1.680e-03\n","Loss: 1.676e-03\n","Loss: 1.673e-03\n","Loss: 1.670e-03\n","Loss: 1.668e-03\n","Loss: 1.666e-03\n","Loss: 1.664e-03\n","Loss: 1.662e-03\n","Loss: 1.660e-03\n","Loss: 1.658e-03\n","Loss: 1.657e-03\n","Loss: 1.654e-03\n","Loss: 1.651e-03\n","Loss: 1.648e-03\n","Loss: 1.646e-03\n","Loss: 1.644e-03\n","Loss: 1.642e-03\n","Loss: 1.641e-03\n","Loss: 1.645e-03\n","Loss: 1.641e-03\n","Loss: 1.640e-03\n","Loss: 1.639e-03\n","Loss: 1.637e-03\n","Loss: 1.635e-03\n","Loss: 1.633e-03\n","Loss: 1.630e-03\n","Loss: 1.627e-03\n","Loss: 1.625e-03\n","Loss: 1.623e-03\n","Loss: 1.621e-03\n","Loss: 1.619e-03\n","Loss: 1.619e-03\n","Loss: 1.617e-03\n","Loss: 1.616e-03\n","Loss: 1.614e-03\n","Loss: 1.613e-03\n","Loss: 1.610e-03\n","Loss: 1.614e-03\n","Loss: 1.609e-03\n","Loss: 1.607e-03\n","Loss: 1.604e-03\n","Loss: 1.605e-03\n","Loss: 1.602e-03\n","Loss: 1.601e-03\n","Loss: 1.601e-03\n","Loss: 1.600e-03\n","Loss: 1.599e-03\n","Loss: 1.597e-03\n","Loss: 1.597e-03\n","Loss: 1.595e-03\n","Loss: 1.594e-03\n","Loss: 1.592e-03\n","Loss: 1.590e-03\n","Loss: 1.588e-03\n","Loss: 1.586e-03\n","Loss: 1.585e-03\n","Loss: 1.582e-03\n","Loss: 1.586e-03\n","Loss: 1.582e-03\n","Loss: 1.581e-03\n","Loss: 1.579e-03\n","Loss: 1.578e-03\n","Loss: 1.577e-03\n","Loss: 1.576e-03\n","Loss: 1.576e-03\n","Loss: 1.575e-03\n","Loss: 1.574e-03\n","Loss: 1.573e-03\n","Loss: 1.571e-03\n","Loss: 1.569e-03\n","Loss: 1.567e-03\n","Loss: 1.566e-03\n","Loss: 1.564e-03\n","Loss: 1.561e-03\n","Loss: 1.560e-03\n","Loss: 1.558e-03\n","Loss: 1.556e-03\n","Loss: 1.555e-03\n","Loss: 1.553e-03\n","Loss: 1.551e-03\n","Loss: 1.550e-03\n","Loss: 1.548e-03\n","Loss: 1.545e-03\n","Loss: 1.540e-03\n","Loss: 1.535e-03\n","Loss: 1.527e-03\n","Loss: 1.522e-03\n","Loss: 1.518e-03\n","Loss: 1.511e-03\n","Loss: 1.571e-03\n","Loss: 1.510e-03\n","Loss: 1.508e-03\n","Loss: 1.505e-03\n","Loss: 1.504e-03\n","Loss: 1.502e-03\n","Loss: 1.499e-03\n","Loss: 1.496e-03\n","Loss: 1.495e-03\n","Loss: 1.492e-03\n","Loss: 1.491e-03\n","Loss: 1.490e-03\n","Loss: 1.488e-03\n","Loss: 1.486e-03\n","Loss: 1.483e-03\n","Loss: 1.480e-03\n","Loss: 1.479e-03\n","Loss: 1.478e-03\n","Loss: 1.476e-03\n","Loss: 1.474e-03\n","Loss: 1.478e-03\n","Loss: 1.473e-03\n","Loss: 1.472e-03\n","Loss: 1.471e-03\n","Loss: 1.470e-03\n","Loss: 1.469e-03\n","Loss: 1.468e-03\n","Loss: 1.507e-03\n","Loss: 1.468e-03\n","Loss: 1.466e-03\n","Loss: 1.465e-03\n","Loss: 1.464e-03\n","Loss: 1.463e-03\n","Loss: 1.462e-03\n","Loss: 1.461e-03\n","Loss: 1.460e-03\n","Loss: 1.469e-03\n","Loss: 1.460e-03\n","Loss: 1.459e-03\n","Loss: 1.458e-03\n","Loss: 1.460e-03\n","Loss: 1.458e-03\n","Loss: 1.457e-03\n","Loss: 1.456e-03\n","Loss: 1.453e-03\n","Loss: 1.470e-03\n","Loss: 1.452e-03\n","Loss: 1.449e-03\n","Loss: 1.447e-03\n","Loss: 1.445e-03\n","Loss: 1.443e-03\n","Loss: 1.439e-03\n","Loss: 1.437e-03\n","Loss: 1.435e-03\n","Loss: 1.434e-03\n","Loss: 1.433e-03\n","Loss: 1.431e-03\n","Loss: 1.430e-03\n","Loss: 1.430e-03\n","Loss: 1.430e-03\n","Loss: 1.429e-03\n","Loss: 1.428e-03\n","Loss: 1.427e-03\n","Loss: 1.425e-03\n","Loss: 1.427e-03\n","Loss: 1.423e-03\n","Loss: 1.421e-03\n","Loss: 1.419e-03\n","Loss: 1.431e-03\n","Loss: 1.418e-03\n","Loss: 1.417e-03\n","Loss: 1.416e-03\n","Loss: 1.415e-03\n","Loss: 1.415e-03\n","Loss: 1.414e-03\n","Loss: 1.412e-03\n","Loss: 1.416e-03\n","Loss: 1.411e-03\n","Loss: 1.410e-03\n","Loss: 1.409e-03\n","Loss: 1.409e-03\n","Loss: 1.408e-03\n","Loss: 1.406e-03\n","Loss: 1.405e-03\n","Loss: 1.403e-03\n","Loss: 1.402e-03\n","Loss: 1.401e-03\n","Loss: 1.401e-03\n","Loss: 1.400e-03\n","Loss: 1.400e-03\n","Loss: 1.398e-03\n","Loss: 1.397e-03\n","Loss: 1.395e-03\n","Loss: 1.393e-03\n","Loss: 1.390e-03\n","Loss: 1.389e-03\n","Loss: 1.388e-03\n","Loss: 1.387e-03\n","Loss: 1.387e-03\n","Loss: 1.386e-03\n","Loss: 1.385e-03\n","Loss: 1.384e-03\n","Loss: 1.382e-03\n","Loss: 1.380e-03\n","Loss: 1.379e-03\n","Loss: 1.378e-03\n","Loss: 1.376e-03\n","Loss: 1.375e-03\n","Loss: 1.373e-03\n","Loss: 1.372e-03\n","Loss: 1.370e-03\n","Loss: 1.369e-03\n","Loss: 1.368e-03\n","Loss: 1.367e-03\n","Loss: 1.367e-03\n","Loss: 1.366e-03\n","Loss: 1.365e-03\n","Loss: 1.363e-03\n","Loss: 1.361e-03\n","Loss: 1.358e-03\n","Loss: 1.355e-03\n","Loss: 1.351e-03\n","Loss: 1.365e-03\n","Loss: 1.350e-03\n","Loss: 1.355e-03\n","Loss: 1.347e-03\n","Loss: 1.343e-03\n","Loss: 1.341e-03\n","Loss: 1.340e-03\n","Loss: 1.339e-03\n","Loss: 1.337e-03\n","Loss: 1.336e-03\n","Loss: 1.334e-03\n","Loss: 1.332e-03\n","Loss: 1.330e-03\n","Loss: 1.328e-03\n","Loss: 1.325e-03\n","Loss: 1.322e-03\n","Loss: 1.321e-03\n","Loss: 1.319e-03\n","Loss: 1.317e-03\n","Loss: 1.314e-03\n","Loss: 1.311e-03\n","Loss: 1.309e-03\n","Loss: 1.308e-03\n","Loss: 1.307e-03\n","Loss: 1.305e-03\n","Loss: 1.309e-03\n","Loss: 1.304e-03\n","Loss: 1.302e-03\n","Loss: 1.300e-03\n","Loss: 1.298e-03\n","Loss: 1.297e-03\n","Loss: 1.296e-03\n","Loss: 1.295e-03\n","Loss: 1.294e-03\n","Loss: 1.292e-03\n","Loss: 1.290e-03\n","Loss: 1.287e-03\n","Loss: 1.285e-03\n","Loss: 1.283e-03\n","Loss: 1.281e-03\n","Loss: 1.280e-03\n","Loss: 1.279e-03\n","Loss: 1.281e-03\n","Loss: 1.278e-03\n","Loss: 1.277e-03\n","Loss: 1.275e-03\n","Loss: 1.274e-03\n","Loss: 1.273e-03\n","Loss: 1.273e-03\n","Loss: 1.272e-03\n","Loss: 1.272e-03\n","Loss: 1.271e-03\n","Loss: 1.270e-03\n","Loss: 1.268e-03\n","Loss: 1.268e-03\n","Loss: 1.267e-03\n","Loss: 1.266e-03\n","Loss: 1.265e-03\n","Loss: 1.263e-03\n","Loss: 1.260e-03\n","Loss: 1.258e-03\n","Loss: 1.255e-03\n","Loss: 1.254e-03\n","Loss: 1.253e-03\n","Loss: 1.252e-03\n","Loss: 1.251e-03\n","Loss: 1.249e-03\n","Loss: 1.249e-03\n","Loss: 1.247e-03\n","Loss: 1.246e-03\n","Loss: 1.245e-03\n","Loss: 1.245e-03\n","Loss: 1.244e-03\n","Loss: 1.243e-03\n","Loss: 1.241e-03\n","Loss: 1.239e-03\n","Loss: 1.236e-03\n","Loss: 1.232e-03\n","Loss: 1.228e-03\n","Loss: 1.224e-03\n","Loss: 1.224e-03\n","Loss: 1.222e-03\n","Loss: 1.219e-03\n","Loss: 1.215e-03\n","Loss: 1.214e-03\n","Loss: 1.212e-03\n","Loss: 1.211e-03\n","Loss: 1.210e-03\n","Loss: 1.208e-03\n","Loss: 1.207e-03\n","Loss: 1.206e-03\n","Loss: 1.206e-03\n","Loss: 1.205e-03\n","Loss: 1.204e-03\n","Loss: 1.202e-03\n","Loss: 1.200e-03\n","Loss: 1.198e-03\n","Loss: 1.197e-03\n","Loss: 1.195e-03\n","Loss: 1.193e-03\n","Loss: 1.190e-03\n","Loss: 1.191e-03\n","Loss: 1.188e-03\n","Loss: 1.186e-03\n","Loss: 1.185e-03\n","Loss: 1.183e-03\n","Loss: 1.182e-03\n","Loss: 1.180e-03\n","Loss: 1.179e-03\n","Loss: 1.178e-03\n","Loss: 1.177e-03\n","Loss: 1.177e-03\n","Loss: 1.176e-03\n","Loss: 1.176e-03\n","Loss: 1.175e-03\n","Loss: 1.174e-03\n","Loss: 1.174e-03\n","Loss: 1.173e-03\n","Loss: 1.172e-03\n","Loss: 1.171e-03\n","Loss: 1.169e-03\n","Loss: 1.167e-03\n","Loss: 1.164e-03\n","Loss: 1.161e-03\n","Loss: 1.158e-03\n","Loss: 1.156e-03\n","Loss: 1.154e-03\n","Loss: 1.152e-03\n","Loss: 1.149e-03\n","Loss: 1.147e-03\n","Loss: 1.146e-03\n","Loss: 1.145e-03\n","Loss: 1.144e-03\n","Loss: 1.143e-03\n","Loss: 1.142e-03\n","Loss: 1.142e-03\n","Loss: 1.141e-03\n","Loss: 1.141e-03\n","Loss: 1.140e-03\n","Loss: 1.139e-03\n","Loss: 1.140e-03\n","Loss: 1.139e-03\n","Loss: 1.138e-03\n","Loss: 1.137e-03\n","Loss: 1.136e-03\n","Loss: 1.136e-03\n","Loss: 1.134e-03\n","Loss: 1.134e-03\n","Loss: 1.133e-03\n","Loss: 1.132e-03\n","Loss: 1.132e-03\n","Loss: 1.131e-03\n","Loss: 1.131e-03\n","Loss: 1.130e-03\n","Loss: 1.129e-03\n","Loss: 1.128e-03\n","Loss: 1.128e-03\n","Loss: 1.128e-03\n","Loss: 1.127e-03\n","Loss: 1.127e-03\n","Loss: 1.127e-03\n","Loss: 1.126e-03\n","Loss: 1.126e-03\n","Loss: 1.126e-03\n","Loss: 1.126e-03\n","Loss: 1.125e-03\n","Loss: 1.125e-03\n","Loss: 1.135e-03\n","Loss: 1.125e-03\n","Loss: 1.124e-03\n","Loss: 1.123e-03\n","Loss: 1.123e-03\n","Loss: 1.121e-03\n","Loss: 1.121e-03\n","Loss: 1.121e-03\n","Loss: 1.120e-03\n","Loss: 1.119e-03\n","Loss: 1.118e-03\n","Loss: 1.117e-03\n","Loss: 1.116e-03\n","Loss: 1.115e-03\n","Loss: 1.115e-03\n","Loss: 1.114e-03\n","Loss: 1.172e-03\n","Loss: 1.113e-03\n","Loss: 1.113e-03\n","Loss: 1.112e-03\n","Loss: 1.112e-03\n","Loss: 1.111e-03\n","Loss: 1.111e-03\n","Loss: 1.111e-03\n","Loss: 1.110e-03\n","Loss: 1.110e-03\n","Loss: 1.109e-03\n","Loss: 1.108e-03\n","Loss: 1.107e-03\n","Loss: 1.107e-03\n","Loss: 1.106e-03\n","Loss: 1.105e-03\n","Loss: 1.103e-03\n","Loss: 1.102e-03\n","Loss: 1.099e-03\n","Loss: 1.098e-03\n","Loss: 1.095e-03\n","Loss: 1.098e-03\n","Loss: 1.095e-03\n","Loss: 1.093e-03\n","Loss: 1.091e-03\n","Loss: 1.088e-03\n","Loss: 1.085e-03\n","Loss: 1.082e-03\n","Loss: 1.079e-03\n","Loss: 1.077e-03\n","Loss: 1.076e-03\n","Loss: 1.073e-03\n","Loss: 1.070e-03\n","Loss: 1.076e-03\n","Loss: 1.069e-03\n","Loss: 1.066e-03\n","Loss: 1.063e-03\n","Loss: 1.060e-03\n","Loss: 1.057e-03\n","Loss: 1.055e-03\n","Loss: 1.053e-03\n","Loss: 1.051e-03\n","Loss: 1.050e-03\n","Loss: 1.047e-03\n","Loss: 1.043e-03\n","Loss: 1.041e-03\n","Loss: 1.040e-03\n","Loss: 1.039e-03\n","Loss: 1.038e-03\n","Loss: 1.036e-03\n","Loss: 1.038e-03\n","Loss: 1.035e-03\n","Loss: 1.032e-03\n","Loss: 1.028e-03\n","Loss: 1.025e-03\n","Loss: 1.022e-03\n","Loss: 1.022e-03\n","Loss: 1.021e-03\n","Loss: 1.019e-03\n","Loss: 1.016e-03\n","Loss: 1.015e-03\n","Loss: 1.013e-03\n","Loss: 1.011e-03\n","Loss: 1.009e-03\n","Loss: 1.008e-03\n","Loss: 1.008e-03\n","Loss: 1.007e-03\n","Loss: 1.005e-03\n","Loss: 1.004e-03\n","Loss: 1.003e-03\n","Loss: 1.003e-03\n","Loss: 1.002e-03\n","Loss: 1.000e-03\n","Loss: 1.021e-03\n","Loss: 9.998e-04\n","Loss: 9.988e-04\n","Loss: 9.982e-04\n","Loss: 9.978e-04\n","Loss: 9.975e-04\n","Loss: 9.970e-04\n","Loss: 9.964e-04\n","Loss: 9.955e-04\n","Loss: 9.953e-04\n","Loss: 9.944e-04\n","Loss: 9.932e-04\n","Loss: 9.927e-04\n","Loss: 9.921e-04\n","Loss: 9.915e-04\n","Loss: 9.908e-04\n","Loss: 9.904e-04\n","Loss: 9.906e-04\n","Loss: 9.901e-04\n","Loss: 9.891e-04\n","Loss: 9.882e-04\n","Loss: 9.900e-04\n","Loss: 9.873e-04\n","Loss: 9.858e-04\n","Loss: 9.851e-04\n","Loss: 9.847e-04\n","Loss: 9.844e-04\n","Loss: 9.840e-04\n","Loss: 9.836e-04\n","Loss: 9.831e-04\n","Loss: 9.829e-04\n","Loss: 9.828e-04\n","Loss: 9.823e-04\n","Loss: 9.821e-04\n","Loss: 9.818e-04\n","Loss: 9.816e-04\n","Loss: 9.812e-04\n","Loss: 9.823e-04\n","Loss: 9.810e-04\n","Loss: 9.806e-04\n","Loss: 9.799e-04\n","Loss: 9.792e-04\n","Loss: 9.787e-04\n","Loss: 9.782e-04\n","Loss: 9.774e-04\n","Loss: 9.770e-04\n","Loss: 9.767e-04\n","Loss: 9.765e-04\n","Loss: 9.762e-04\n","Loss: 9.757e-04\n","Loss: 9.750e-04\n","Loss: 9.745e-04\n","Loss: 9.739e-04\n","Loss: 9.729e-04\n","Loss: 9.721e-04\n","Loss: 9.712e-04\n","Loss: 9.702e-04\n","Loss: 9.694e-04\n","Loss: 9.680e-04\n","Loss: 9.669e-04\n","Loss: 9.650e-04\n","Loss: 9.624e-04\n","Loss: 9.618e-04\n","Loss: 9.612e-04\n","Loss: 9.602e-04\n","Loss: 9.591e-04\n","Loss: 9.577e-04\n","Loss: 9.571e-04\n","Loss: 9.561e-04\n","Loss: 9.555e-04\n","Loss: 9.550e-04\n","Loss: 9.543e-04\n","Loss: 9.536e-04\n","Loss: 9.527e-04\n","Loss: 9.516e-04\n","Loss: 9.507e-04\n","Loss: 9.502e-04\n","Loss: 9.525e-04\n","Loss: 9.497e-04\n","Loss: 9.489e-04\n","Loss: 9.478e-04\n","Loss: 9.466e-04\n","Loss: 9.456e-04\n","Loss: 9.446e-04\n","Loss: 9.437e-04\n","Loss: 9.425e-04\n","Loss: 9.412e-04\n","Loss: 9.753e-04\n","Loss: 9.409e-04\n","Loss: 9.398e-04\n","Loss: 9.388e-04\n","Loss: 9.380e-04\n","Loss: 9.366e-04\n","Loss: 9.377e-04\n","Loss: 9.360e-04\n","Loss: 9.350e-04\n","Loss: 9.340e-04\n","Loss: 9.335e-04\n","Loss: 9.329e-04\n","Loss: 9.329e-04\n","Loss: 9.322e-04\n","Loss: 9.319e-04\n","Loss: 9.315e-04\n","Loss: 9.310e-04\n","Loss: 9.306e-04\n","Loss: 9.300e-04\n","Loss: 9.291e-04\n","Loss: 9.280e-04\n","Loss: 9.271e-04\n","Loss: 9.262e-04\n","Loss: 9.250e-04\n","Loss: 9.241e-04\n","Loss: 9.229e-04\n","Loss: 9.218e-04\n","Loss: 9.202e-04\n","Loss: 9.186e-04\n","Loss: 9.161e-04\n","Loss: 9.119e-04\n","Loss: 9.097e-04\n","Loss: 9.087e-04\n","Loss: 9.082e-04\n","Loss: 9.078e-04\n","Loss: 9.074e-04\n","Loss: 9.070e-04\n","Loss: 9.065e-04\n","Loss: 9.062e-04\n","Loss: 9.057e-04\n","Loss: 9.055e-04\n","Loss: 9.053e-04\n","Loss: 9.051e-04\n","Loss: 9.049e-04\n","Loss: 9.047e-04\n","Loss: 9.046e-04\n","Loss: 9.044e-04\n","Loss: 9.043e-04\n","Loss: 9.039e-04\n","Loss: 9.035e-04\n","Loss: 9.025e-04\n","Loss: 9.024e-04\n","Loss: 9.012e-04\n","Loss: 9.005e-04\n","Loss: 8.997e-04\n","Loss: 8.985e-04\n","Loss: 8.961e-04\n","Loss: 8.934e-04\n","Loss: 8.913e-04\n","Loss: 8.898e-04\n","Loss: 8.888e-04\n","Loss: 8.880e-04\n","Loss: 8.869e-04\n","Loss: 8.865e-04\n","Loss: 8.857e-04\n","Loss: 8.853e-04\n","Loss: 8.850e-04\n","Loss: 8.848e-04\n","Loss: 8.845e-04\n","Loss: 8.840e-04\n","Loss: 8.836e-04\n","Loss: 8.832e-04\n","Loss: 8.829e-04\n","Loss: 8.847e-04\n","Loss: 8.828e-04\n","Loss: 8.823e-04\n","Loss: 8.821e-04\n","Loss: 8.817e-04\n","Loss: 8.813e-04\n","Loss: 8.805e-04\n","Loss: 8.792e-04\n","Loss: 8.780e-04\n","Loss: 8.789e-04\n","Loss: 8.773e-04\n","Loss: 8.766e-04\n","Loss: 8.760e-04\n","Loss: 8.751e-04\n","Loss: 8.736e-04\n","Loss: 8.728e-04\n","Loss: 8.731e-04\n","Loss: 8.723e-04\n","Loss: 8.712e-04\n","Loss: 8.700e-04\n","Loss: 8.692e-04\n","Loss: 8.709e-04\n","Loss: 8.689e-04\n","Loss: 8.681e-04\n","Loss: 8.673e-04\n","Loss: 8.666e-04\n","Loss: 8.655e-04\n","Loss: 8.642e-04\n","Loss: 8.625e-04\n","Loss: 8.798e-04\n","Loss: 8.622e-04\n","Loss: 8.606e-04\n","Loss: 8.592e-04\n","Loss: 8.578e-04\n","Loss: 8.562e-04\n","Loss: 8.546e-04\n","Loss: 8.545e-04\n","Loss: 8.534e-04\n","Loss: 8.531e-04\n","Loss: 8.526e-04\n","Loss: 8.521e-04\n","Loss: 8.516e-04\n","Loss: 8.546e-04\n","Loss: 8.510e-04\n","Loss: 8.504e-04\n","Loss: 8.501e-04\n","Loss: 8.493e-04\n","Loss: 8.489e-04\n","Loss: 8.481e-04\n","Loss: 8.470e-04\n","Loss: 8.464e-04\n","Loss: 8.456e-04\n","Loss: 8.453e-04\n","Loss: 8.450e-04\n","Loss: 8.446e-04\n","Loss: 8.440e-04\n","Loss: 8.434e-04\n","Loss: 8.438e-04\n","Loss: 8.430e-04\n","Loss: 8.427e-04\n","Loss: 8.423e-04\n","Loss: 8.420e-04\n","Loss: 8.414e-04\n","Loss: 8.407e-04\n","Loss: 8.401e-04\n","Loss: 8.396e-04\n","Loss: 8.392e-04\n","Loss: 8.391e-04\n","Loss: 8.389e-04\n","Loss: 8.387e-04\n","Loss: 8.385e-04\n","Loss: 8.383e-04\n","Loss: 8.378e-04\n","Loss: 8.371e-04\n","Loss: 8.367e-04\n","Loss: 8.358e-04\n","Loss: 8.352e-04\n","Loss: 8.346e-04\n","Loss: 8.339e-04\n","Loss: 8.333e-04\n","Loss: 8.325e-04\n","Loss: 8.320e-04\n","Loss: 8.315e-04\n","Loss: 8.309e-04\n","Loss: 8.297e-04\n","Loss: 8.287e-04\n","Loss: 8.269e-04\n","Loss: 8.259e-04\n","Loss: 8.246e-04\n","Loss: 8.238e-04\n","Loss: 8.229e-04\n","Loss: 8.224e-04\n","Loss: 8.217e-04\n","Loss: 8.205e-04\n","Loss: 8.193e-04\n","Loss: 8.174e-04\n","Loss: 8.170e-04\n","Loss: 8.159e-04\n","Loss: 8.154e-04\n","Loss: 8.149e-04\n","Loss: 8.144e-04\n","Loss: 8.141e-04\n","Loss: 8.137e-04\n","Loss: 8.133e-04\n","Loss: 8.129e-04\n","Loss: 8.125e-04\n","Loss: 8.119e-04\n","Loss: 8.116e-04\n","Loss: 8.112e-04\n","Loss: 8.109e-04\n","Loss: 8.106e-04\n","Loss: 8.102e-04\n","Loss: 8.097e-04\n","Loss: 8.093e-04\n","Loss: 8.089e-04\n","Loss: 8.086e-04\n","Loss: 8.083e-04\n","Loss: 8.080e-04\n","Loss: 8.077e-04\n","Loss: 8.083e-04\n","Loss: 8.076e-04\n","Loss: 8.073e-04\n","Loss: 8.070e-04\n","Loss: 8.068e-04\n","Loss: 8.065e-04\n","Loss: 8.060e-04\n","Loss: 8.054e-04\n","Loss: 8.098e-04\n","Loss: 8.051e-04\n","Loss: 8.047e-04\n","Loss: 8.041e-04\n","Loss: 8.038e-04\n","Loss: 8.030e-04\n","Loss: 8.036e-04\n","Loss: 8.029e-04\n","Loss: 8.026e-04\n","Loss: 8.024e-04\n","Loss: 8.020e-04\n","Loss: 8.015e-04\n","Loss: 8.010e-04\n","Loss: 8.003e-04\n","Loss: 7.995e-04\n","Loss: 7.989e-04\n","Loss: 7.981e-04\n","Loss: 7.977e-04\n","Loss: 7.972e-04\n","Loss: 7.969e-04\n","Loss: 7.964e-04\n","Loss: 7.959e-04\n","Loss: 7.952e-04\n","Loss: 7.948e-04\n","Loss: 7.944e-04\n","Loss: 7.940e-04\n","Loss: 7.937e-04\n","Loss: 7.937e-04\n","Loss: 7.934e-04\n","Loss: 7.927e-04\n","Loss: 7.921e-04\n","Loss: 7.915e-04\n","Loss: 7.908e-04\n","Loss: 7.898e-04\n","Loss: 7.900e-04\n","Loss: 7.893e-04\n","Loss: 7.886e-04\n","Loss: 7.878e-04\n","Loss: 7.874e-04\n","Loss: 7.866e-04\n","Loss: 7.857e-04\n","Loss: 7.851e-04\n","Loss: 7.844e-04\n","Loss: 7.838e-04\n","Loss: 7.829e-04\n","Loss: 7.823e-04\n","Loss: 7.820e-04\n","Loss: 7.815e-04\n","Loss: 7.811e-04\n","Loss: 7.810e-04\n","Loss: 7.801e-04\n","Loss: 7.798e-04\n","Loss: 7.794e-04\n","Loss: 7.792e-04\n","Loss: 7.784e-04\n","Loss: 7.779e-04\n","Loss: 7.774e-04\n","Loss: 7.767e-04\n","Loss: 7.762e-04\n","Loss: 7.752e-04\n","Loss: 7.746e-04\n","Loss: 7.737e-04\n","Loss: 7.738e-04\n","Loss: 7.731e-04\n","Loss: 7.725e-04\n","Loss: 7.717e-04\n","Loss: 7.710e-04\n","Loss: 7.703e-04\n","Loss: 7.696e-04\n","Loss: 7.692e-04\n","Loss: 7.681e-04\n","Loss: 7.667e-04\n","Loss: 7.718e-04\n","Loss: 7.663e-04\n","Loss: 7.649e-04\n","Loss: 7.632e-04\n","Loss: 7.620e-04\n","Loss: 7.611e-04\n","Loss: 7.603e-04\n","Loss: 7.589e-04\n","Loss: 7.583e-04\n","Loss: 7.565e-04\n","Loss: 7.552e-04\n","Loss: 7.536e-04\n","Loss: 7.557e-04\n","Loss: 7.526e-04\n","Loss: 7.510e-04\n","Loss: 7.488e-04\n","Loss: 7.478e-04\n","Loss: 7.466e-04\n","Loss: 7.455e-04\n","Loss: 7.439e-04\n","Loss: 7.429e-04\n","Loss: 7.420e-04\n","Loss: 7.408e-04\n","Loss: 7.401e-04\n","Loss: 7.388e-04\n","Loss: 7.381e-04\n","Loss: 7.374e-04\n","Loss: 7.360e-04\n","Loss: 7.350e-04\n","Loss: 7.337e-04\n","Loss: 7.316e-04\n","Loss: 7.304e-04\n","Loss: 7.270e-04\n","Loss: 7.250e-04\n","Loss: 7.233e-04\n","Loss: 7.218e-04\n","Loss: 7.208e-04\n","Loss: 7.198e-04\n","Loss: 7.192e-04\n","Loss: 7.186e-04\n","Loss: 7.178e-04\n","Loss: 7.173e-04\n","Loss: 7.166e-04\n","Loss: 7.156e-04\n","Loss: 7.141e-04\n","Loss: 7.132e-04\n","Loss: 7.123e-04\n","Loss: 7.110e-04\n","Loss: 7.105e-04\n","Loss: 7.104e-04\n","Loss: 7.102e-04\n","Loss: 7.100e-04\n","Loss: 7.097e-04\n","Loss: 7.091e-04\n","Loss: 7.087e-04\n","Loss: 7.079e-04\n","Loss: 7.075e-04\n","Loss: 7.072e-04\n","Loss: 7.069e-04\n","Loss: 7.064e-04\n","Loss: 7.061e-04\n","Loss: 7.057e-04\n","Loss: 7.053e-04\n","Loss: 7.050e-04\n","Loss: 7.047e-04\n","Loss: 7.044e-04\n","Loss: 7.042e-04\n","Loss: 7.039e-04\n","Loss: 7.037e-04\n","Loss: 7.034e-04\n","Loss: 7.031e-04\n","Loss: 7.027e-04\n","Loss: 7.041e-04\n","Loss: 7.024e-04\n","Loss: 7.020e-04\n","Loss: 7.015e-04\n","Loss: 7.011e-04\n","Loss: 7.004e-04\n","Loss: 6.996e-04\n","Loss: 6.988e-04\n","Loss: 6.980e-04\n","Loss: 6.971e-04\n","Loss: 6.964e-04\n","Loss: 6.958e-04\n","Loss: 6.954e-04\n","Loss: 6.949e-04\n","Loss: 6.946e-04\n","Loss: 6.943e-04\n","Loss: 6.942e-04\n","Loss: 6.941e-04\n","Loss: 6.939e-04\n","Loss: 6.937e-04\n","Loss: 6.938e-04\n","Loss: 6.935e-04\n","Loss: 6.932e-04\n","Loss: 6.929e-04\n","Loss: 6.926e-04\n","Loss: 6.923e-04\n","Loss: 6.930e-04\n","Loss: 6.922e-04\n","Loss: 6.919e-04\n","Loss: 6.915e-04\n","Loss: 6.911e-04\n","Loss: 6.907e-04\n","Loss: 6.901e-04\n","Loss: 6.891e-04\n","Loss: 7.051e-04\n","Loss: 6.887e-04\n","Loss: 6.877e-04\n","Loss: 6.870e-04\n","Loss: 6.868e-04\n","Loss: 6.863e-04\n","Loss: 6.859e-04\n","Loss: 6.851e-04\n","Loss: 6.844e-04\n","Loss: 6.838e-04\n","Loss: 6.829e-04\n","Loss: 6.816e-04\n","Loss: 6.809e-04\n","Loss: 6.803e-04\n","Loss: 6.798e-04\n","Loss: 6.792e-04\n","Loss: 6.782e-04\n","Loss: 6.771e-04\n","Loss: 6.765e-04\n","Loss: 6.760e-04\n","Loss: 6.755e-04\n","Loss: 6.749e-04\n","Loss: 6.739e-04\n","Loss: 6.729e-04\n","Loss: 6.723e-04\n","Loss: 6.715e-04\n","Loss: 6.709e-04\n","Loss: 6.704e-04\n","Loss: 6.697e-04\n","Loss: 6.688e-04\n","Loss: 6.678e-04\n","Loss: 6.669e-04\n","Loss: 6.659e-04\n","Loss: 6.651e-04\n","Loss: 6.646e-04\n","Loss: 6.640e-04\n","Loss: 6.636e-04\n","Loss: 6.633e-04\n","Loss: 6.631e-04\n","Loss: 6.625e-04\n","Loss: 6.622e-04\n","Loss: 6.618e-04\n","Loss: 6.615e-04\n","Loss: 6.612e-04\n","Loss: 6.608e-04\n","Loss: 6.607e-04\n","Loss: 6.603e-04\n","Loss: 6.598e-04\n","Loss: 6.606e-04\n","Loss: 6.595e-04\n","Loss: 6.589e-04\n","Loss: 6.584e-04\n","Loss: 6.579e-04\n","Loss: 6.573e-04\n","Loss: 6.566e-04\n","Loss: 6.562e-04\n","Loss: 6.556e-04\n","Loss: 6.553e-04\n","Loss: 6.543e-04\n","Loss: 6.534e-04\n","Loss: 6.530e-04\n","Loss: 6.518e-04\n","Loss: 6.512e-04\n","Loss: 6.506e-04\n","Loss: 6.499e-04\n","Loss: 6.493e-04\n","Loss: 6.487e-04\n","Loss: 6.480e-04\n","Loss: 6.468e-04\n","Loss: 6.498e-04\n","Loss: 6.462e-04\n","Loss: 6.455e-04\n","Loss: 6.448e-04\n","Loss: 6.439e-04\n","Loss: 6.433e-04\n","Loss: 6.422e-04\n","Loss: 6.413e-04\n","Loss: 6.403e-04\n","Loss: 6.404e-04\n","Loss: 6.400e-04\n","Loss: 6.396e-04\n","Loss: 6.394e-04\n","Loss: 6.390e-04\n","Loss: 6.388e-04\n","Loss: 6.381e-04\n","Loss: 6.374e-04\n","Loss: 6.360e-04\n","Loss: 6.402e-04\n","Loss: 6.351e-04\n","Loss: 6.334e-04\n","Loss: 6.434e-04\n","Loss: 6.326e-04\n","Loss: 6.310e-04\n","Loss: 6.304e-04\n","Loss: 6.295e-04\n","Loss: 6.290e-04\n","Loss: 6.284e-04\n","Loss: 6.279e-04\n","Loss: 6.281e-04\n","Loss: 6.276e-04\n","Loss: 6.269e-04\n","Loss: 6.260e-04\n","Loss: 6.257e-04\n","Loss: 6.253e-04\n","Loss: 6.249e-04\n","Loss: 6.245e-04\n","Loss: 6.238e-04\n","Loss: 6.230e-04\n","Loss: 6.214e-04\n","Loss: 6.200e-04\n","Loss: 6.190e-04\n","Loss: 6.178e-04\n","Loss: 6.172e-04\n","Loss: 6.161e-04\n","Loss: 6.152e-04\n","Loss: 6.140e-04\n","Loss: 6.127e-04\n","Loss: 6.113e-04\n","Loss: 6.120e-04\n","Loss: 6.101e-04\n","Loss: 6.091e-04\n","Loss: 6.085e-04\n","Loss: 6.079e-04\n","Loss: 6.058e-04\n","Loss: 6.037e-04\n","Loss: 6.026e-04\n","Loss: 6.019e-04\n","Loss: 6.015e-04\n","Loss: 6.011e-04\n","Loss: 6.006e-04\n","Loss: 6.000e-04\n","Loss: 6.035e-04\n","Loss: 5.997e-04\n","Loss: 5.991e-04\n","Loss: 5.983e-04\n","Loss: 5.974e-04\n","Loss: 5.963e-04\n","Loss: 5.950e-04\n","Loss: 5.934e-04\n","Loss: 5.935e-04\n","Loss: 5.931e-04\n","Loss: 5.927e-04\n","Loss: 5.921e-04\n","Loss: 5.917e-04\n","Loss: 5.914e-04\n","Loss: 5.912e-04\n","Loss: 5.909e-04\n","Loss: 5.905e-04\n","Loss: 5.899e-04\n","Loss: 5.902e-04\n","Loss: 5.896e-04\n","Loss: 5.891e-04\n","Loss: 5.887e-04\n","Loss: 5.883e-04\n","Loss: 5.876e-04\n","Loss: 5.868e-04\n","Loss: 5.907e-04\n","Loss: 5.863e-04\n","Loss: 5.864e-04\n","Loss: 5.857e-04\n","Loss: 5.845e-04\n","Loss: 5.837e-04\n","Loss: 5.830e-04\n","Loss: 5.828e-04\n","Loss: 5.826e-04\n","Loss: 5.825e-04\n","Loss: 5.822e-04\n","Loss: 5.818e-04\n","Loss: 5.815e-04\n","Loss: 5.811e-04\n","Loss: 5.807e-04\n","Loss: 5.800e-04\n","Loss: 5.793e-04\n","Loss: 5.789e-04\n","Loss: 5.785e-04\n","Loss: 5.781e-04\n","Loss: 5.775e-04\n","Loss: 5.767e-04\n","Loss: 5.755e-04\n","Loss: 5.744e-04\n","Loss: 5.737e-04\n","Loss: 5.735e-04\n","Loss: 5.730e-04\n","Loss: 5.748e-04\n","Loss: 5.729e-04\n","Loss: 5.725e-04\n","Loss: 5.718e-04\n","Loss: 5.711e-04\n","Loss: 5.707e-04\n","Loss: 5.700e-04\n","Loss: 5.690e-04\n","Loss: 5.681e-04\n","Loss: 5.672e-04\n","Loss: 5.666e-04\n","Loss: 5.659e-04\n","Loss: 5.655e-04\n","Loss: 5.648e-04\n","Loss: 5.652e-04\n","Loss: 5.643e-04\n","Loss: 5.634e-04\n","Loss: 5.623e-04\n","Loss: 5.615e-04\n","Loss: 5.603e-04\n","Loss: 5.590e-04\n","Loss: 5.570e-04\n","Loss: 5.606e-04\n","Loss: 5.559e-04\n","Loss: 5.551e-04\n","Loss: 5.534e-04\n","Loss: 5.528e-04\n","Loss: 5.516e-04\n","Loss: 5.505e-04\n","Loss: 5.494e-04\n","Loss: 5.492e-04\n","Loss: 5.478e-04\n","Loss: 5.472e-04\n","Loss: 5.469e-04\n","Loss: 5.465e-04\n","Loss: 5.461e-04\n","Loss: 5.457e-04\n","Loss: 5.453e-04\n","Loss: 5.453e-04\n","Loss: 5.448e-04\n","Loss: 5.439e-04\n","Loss: 5.430e-04\n","Loss: 5.421e-04\n","Loss: 5.415e-04\n","Loss: 5.407e-04\n","Loss: 5.398e-04\n","Loss: 5.391e-04\n","Loss: 5.377e-04\n","Loss: 5.368e-04\n","Loss: 5.356e-04\n","Loss: 5.339e-04\n","Loss: 5.327e-04\n","Loss: 5.320e-04\n","Loss: 5.315e-04\n","Loss: 5.310e-04\n","Loss: 5.304e-04\n","Loss: 5.300e-04\n","Loss: 5.295e-04\n","Loss: 5.285e-04\n","Loss: 5.278e-04\n","Loss: 5.268e-04\n","Loss: 5.259e-04\n","Loss: 5.255e-04\n","Loss: 5.247e-04\n","Loss: 5.240e-04\n","Loss: 5.228e-04\n","Loss: 5.211e-04\n","Loss: 5.209e-04\n","Loss: 5.202e-04\n","Loss: 5.190e-04\n","Loss: 5.182e-04\n","Loss: 5.175e-04\n","Loss: 5.170e-04\n","Loss: 5.171e-04\n","Loss: 5.168e-04\n","Loss: 5.165e-04\n","Loss: 5.163e-04\n","Loss: 5.160e-04\n","Loss: 5.156e-04\n","Loss: 5.154e-04\n","Loss: 5.175e-04\n","Loss: 5.152e-04\n","Loss: 5.150e-04\n","Loss: 5.149e-04\n","Loss: 5.148e-04\n","Loss: 5.146e-04\n","Loss: 5.142e-04\n","Loss: 5.139e-04\n","Loss: 5.136e-04\n","Loss: 5.134e-04\n","Loss: 5.132e-04\n","Loss: 5.173e-04\n","Loss: 5.131e-04\n","Loss: 5.127e-04\n","Loss: 5.125e-04\n","Loss: 5.122e-04\n","Loss: 5.119e-04\n","Loss: 5.114e-04\n","Loss: 5.127e-04\n","Loss: 5.113e-04\n","Loss: 5.107e-04\n","Loss: 5.104e-04\n","Loss: 5.101e-04\n","Loss: 5.098e-04\n","Loss: 5.124e-04\n","Loss: 5.097e-04\n","Loss: 5.094e-04\n","Loss: 5.092e-04\n","Loss: 5.090e-04\n","Loss: 5.089e-04\n","Loss: 5.086e-04\n","Loss: 5.083e-04\n","Loss: 5.078e-04\n","Loss: 5.071e-04\n","Loss: 5.065e-04\n","Loss: 5.061e-04\n","Loss: 5.056e-04\n","Loss: 5.051e-04\n","Loss: 5.041e-04\n","Loss: 5.036e-04\n","Loss: 5.032e-04\n","Loss: 5.030e-04\n","Loss: 5.027e-04\n","Loss: 5.022e-04\n","Loss: 5.019e-04\n","Loss: 5.016e-04\n","Loss: 5.015e-04\n","Loss: 5.012e-04\n","Loss: 5.009e-04\n","Loss: 5.005e-04\n","Loss: 5.001e-04\n","Loss: 4.997e-04\n","Loss: 4.994e-04\n","Loss: 4.993e-04\n","Loss: 4.990e-04\n","Loss: 4.988e-04\n","Loss: 4.984e-04\n","Loss: 4.980e-04\n","Loss: 4.975e-04\n","Loss: 4.974e-04\n","Loss: 4.977e-04\n","Loss: 4.970e-04\n","Loss: 4.966e-04\n","Loss: 4.967e-04\n","Loss: 4.964e-04\n","Loss: 4.961e-04\n","Loss: 4.957e-04\n","Loss: 4.953e-04\n","Loss: 4.949e-04\n","Loss: 4.954e-04\n","Loss: 4.946e-04\n","Loss: 4.940e-04\n","Loss: 4.921e-04\n","Loss: 4.917e-04\n","Loss: 4.914e-04\n","Loss: 4.911e-04\n","Loss: 4.909e-04\n","Loss: 4.905e-04\n","Loss: 4.902e-04\n","Loss: 4.898e-04\n","Loss: 4.893e-04\n","Loss: 4.890e-04\n","Loss: 4.886e-04\n","Loss: 4.885e-04\n","Loss: 4.884e-04\n","Loss: 4.882e-04\n","Loss: 4.879e-04\n","Loss: 4.876e-04\n","Loss: 4.873e-04\n","Loss: 4.865e-04\n","Loss: 4.862e-04\n","Loss: 4.860e-04\n","Loss: 4.856e-04\n","Loss: 4.855e-04\n","Loss: 4.851e-04\n","Loss: 4.850e-04\n","Loss: 4.846e-04\n","Loss: 4.843e-04\n","Loss: 4.841e-04\n","Loss: 4.839e-04\n","Loss: 4.836e-04\n","Loss: 4.834e-04\n","Loss: 4.832e-04\n","Loss: 4.829e-04\n","Loss: 4.829e-04\n","Loss: 4.825e-04\n","Loss: 4.824e-04\n","Loss: 4.822e-04\n","Loss: 4.907e-04\n","Loss: 4.821e-04\n","Loss: 4.820e-04\n","Loss: 4.819e-04\n","Loss: 4.817e-04\n","Loss: 4.814e-04\n","Loss: 4.811e-04\n","Loss: 4.809e-04\n","Loss: 4.806e-04\n","Loss: 4.804e-04\n","Loss: 4.802e-04\n","Loss: 4.799e-04\n","Loss: 4.795e-04\n","Loss: 4.792e-04\n","Loss: 4.791e-04\n","Loss: 4.789e-04\n","Loss: 4.788e-04\n","Loss: 4.786e-04\n","Loss: 4.783e-04\n","Loss: 4.778e-04\n","Loss: 4.789e-04\n","Loss: 4.775e-04\n","Loss: 4.772e-04\n","Loss: 4.769e-04\n","Loss: 4.768e-04\n","Loss: 4.766e-04\n","Loss: 4.764e-04\n","Loss: 4.774e-04\n","Loss: 4.762e-04\n","Loss: 4.760e-04\n","Loss: 4.758e-04\n","Loss: 4.756e-04\n","Loss: 4.752e-04\n","Loss: 4.747e-04\n","Loss: 4.787e-04\n","Loss: 4.745e-04\n","Loss: 4.739e-04\n","Loss: 4.735e-04\n","Loss: 4.733e-04\n","Loss: 4.731e-04\n","Loss: 4.728e-04\n","Loss: 4.724e-04\n","Loss: 4.720e-04\n","Loss: 4.717e-04\n","Loss: 4.715e-04\n","Loss: 4.712e-04\n","Loss: 4.705e-04\n","Loss: 4.700e-04\n","Loss: 4.693e-04\n","Loss: 4.689e-04\n","Loss: 4.684e-04\n","Loss: 4.681e-04\n","Loss: 4.675e-04\n","Loss: 4.678e-04\n","Loss: 4.674e-04\n","Loss: 4.671e-04\n","Loss: 4.664e-04\n","Loss: 5.286e-04\n","Loss: 4.662e-04\n","Loss: 4.656e-04\n","Loss: 4.649e-04\n","Loss: 4.644e-04\n","Loss: 4.635e-04\n","Loss: 4.628e-04\n","Loss: 4.655e-04\n","Loss: 4.624e-04\n","Loss: 4.617e-04\n","Loss: 4.612e-04\n","Loss: 4.608e-04\n","Loss: 4.601e-04\n","Loss: 4.593e-04\n","Loss: 4.584e-04\n","Loss: 4.578e-04\n","Loss: 4.573e-04\n","Loss: 4.571e-04\n","Loss: 4.568e-04\n","Loss: 4.566e-04\n","Loss: 4.560e-04\n","Loss: 4.555e-04\n","Loss: 4.550e-04\n","Loss: 4.546e-04\n","Loss: 4.542e-04\n","Loss: 4.541e-04\n","Loss: 4.538e-04\n","Loss: 4.535e-04\n","Loss: 4.531e-04\n","Loss: 4.528e-04\n","Loss: 4.524e-04\n","Loss: 4.520e-04\n","Loss: 4.514e-04\n","Loss: 4.508e-04\n","Loss: 4.492e-04\n","Loss: 4.552e-04\n","Loss: 4.490e-04\n","Loss: 4.482e-04\n","Loss: 4.468e-04\n","Loss: 4.461e-04\n","Loss: 4.456e-04\n","Loss: 4.450e-04\n","Loss: 4.443e-04\n","Loss: 4.437e-04\n","Loss: 4.432e-04\n","Loss: 4.428e-04\n","Loss: 4.420e-04\n","Loss: 4.411e-04\n","Loss: 4.402e-04\n","Loss: 4.394e-04\n","Loss: 4.391e-04\n","Loss: 4.386e-04\n","Loss: 4.384e-04\n","Loss: 4.382e-04\n","Loss: 4.377e-04\n","Loss: 4.373e-04\n","Loss: 4.368e-04\n","Loss: 4.365e-04\n","Loss: 4.361e-04\n","Loss: 4.359e-04\n","Loss: 4.354e-04\n","Loss: 4.349e-04\n","Loss: 4.345e-04\n","Loss: 4.341e-04\n","Loss: 4.341e-04\n","Loss: 4.338e-04\n","Loss: 4.333e-04\n","Loss: 4.329e-04\n","Loss: 4.322e-04\n","Loss: 4.314e-04\n","Loss: 4.306e-04\n","Loss: 4.301e-04\n","Loss: 4.297e-04\n","Loss: 4.295e-04\n","Loss: 4.292e-04\n","Loss: 4.287e-04\n","Loss: 4.284e-04\n","Loss: 4.280e-04\n","Loss: 4.278e-04\n","Loss: 4.274e-04\n","Loss: 4.271e-04\n","Loss: 4.267e-04\n","Loss: 4.262e-04\n","Loss: 4.257e-04\n","Loss: 4.253e-04\n","Loss: 4.250e-04\n","Loss: 4.248e-04\n","Loss: 4.244e-04\n","Loss: 4.243e-04\n","Loss: 4.241e-04\n","Loss: 4.240e-04\n","Loss: 4.237e-04\n","Loss: 4.234e-04\n","Loss: 4.229e-04\n","Loss: 4.225e-04\n","Loss: 4.220e-04\n","Loss: 4.217e-04\n","Loss: 4.216e-04\n","Loss: 4.212e-04\n","Loss: 4.211e-04\n","Loss: 4.207e-04\n","Loss: 4.202e-04\n","Loss: 4.195e-04\n","Loss: 4.264e-04\n","Loss: 4.194e-04\n","Loss: 4.188e-04\n","Loss: 4.183e-04\n","Loss: 4.178e-04\n","Loss: 4.172e-04\n","Loss: 4.348e-04\n","Loss: 4.171e-04\n","Loss: 4.165e-04\n","Loss: 4.161e-04\n","Loss: 4.159e-04\n","Loss: 4.155e-04\n","Loss: 4.151e-04\n","Loss: 4.145e-04\n","Loss: 4.136e-04\n","Loss: 4.130e-04\n","Loss: 4.126e-04\n","Loss: 4.121e-04\n","Loss: 4.118e-04\n","Loss: 4.115e-04\n","Loss: 4.116e-04\n","Loss: 4.114e-04\n","Loss: 4.112e-04\n","Loss: 4.111e-04\n","Loss: 4.109e-04\n","Loss: 4.107e-04\n","Loss: 4.119e-04\n","Loss: 4.106e-04\n","Loss: 4.104e-04\n","Loss: 4.103e-04\n","Loss: 4.102e-04\n","Loss: 4.101e-04\n","Loss: 4.099e-04\n","Loss: 4.095e-04\n","Loss: 4.096e-04\n","Loss: 4.092e-04\n","Loss: 4.086e-04\n","Loss: 4.080e-04\n","Loss: 4.075e-04\n","Loss: 4.071e-04\n","Loss: 4.064e-04\n","Loss: 4.058e-04\n","Loss: 4.053e-04\n","Loss: 4.049e-04\n","Loss: 4.047e-04\n","Loss: 4.043e-04\n","Loss: 4.040e-04\n","Loss: 4.033e-04\n","Loss: 4.029e-04\n","Loss: 4.027e-04\n","Loss: 4.025e-04\n","Loss: 4.029e-04\n","Loss: 4.022e-04\n","Loss: 4.017e-04\n","Loss: 4.014e-04\n","Loss: 4.007e-04\n","Loss: 4.002e-04\n","Loss: 3.992e-04\n","Loss: 4.189e-04\n","Loss: 3.990e-04\n","Loss: 3.984e-04\n","Loss: 3.974e-04\n","Loss: 3.964e-04\n","Loss: 3.977e-04\n","Loss: 3.963e-04\n","Loss: 3.959e-04\n","Loss: 3.956e-04\n","Loss: 3.954e-04\n","Loss: 3.952e-04\n","Loss: 3.950e-04\n","Loss: 3.947e-04\n","Loss: 3.944e-04\n","Loss: 3.941e-04\n","Loss: 3.939e-04\n","Loss: 3.952e-04\n","Loss: 3.938e-04\n","Loss: 3.935e-04\n","Loss: 3.933e-04\n","Loss: 3.927e-04\n","Loss: 3.924e-04\n","Loss: 3.921e-04\n","Loss: 3.918e-04\n","Loss: 3.914e-04\n","Loss: 3.908e-04\n","Loss: 3.903e-04\n","Loss: 3.896e-04\n","Loss: 3.891e-04\n","Loss: 3.886e-04\n","Loss: 3.878e-04\n","Loss: 3.886e-04\n","Loss: 3.876e-04\n","Loss: 3.874e-04\n","Loss: 3.868e-04\n","Loss: 3.866e-04\n","Loss: 3.865e-04\n","Loss: 3.862e-04\n","Loss: 3.859e-04\n","Loss: 3.855e-04\n","Loss: 3.852e-04\n","Loss: 3.850e-04\n","Loss: 3.852e-04\n","Loss: 3.847e-04\n","Loss: 3.845e-04\n","Loss: 3.841e-04\n","Loss: 3.838e-04\n","Loss: 3.832e-04\n","Loss: 3.833e-04\n","Loss: 3.828e-04\n","Loss: 3.823e-04\n","Loss: 3.818e-04\n","Loss: 3.816e-04\n","Loss: 3.813e-04\n","Loss: 3.809e-04\n","Loss: 3.804e-04\n","Loss: 3.801e-04\n","Loss: 3.799e-04\n","Loss: 3.797e-04\n","Loss: 3.795e-04\n","Loss: 3.793e-04\n","Loss: 3.790e-04\n","Loss: 3.790e-04\n","Loss: 3.788e-04\n","Loss: 3.785e-04\n","Loss: 3.783e-04\n","Loss: 3.781e-04\n","Loss: 3.779e-04\n","Loss: 3.778e-04\n","Loss: 3.775e-04\n","Loss: 3.772e-04\n","Loss: 3.769e-04\n","Loss: 3.765e-04\n","Loss: 3.763e-04\n","Loss: 3.761e-04\n","Loss: 3.758e-04\n","Loss: 3.755e-04\n","Loss: 3.752e-04\n","Loss: 3.750e-04\n","Loss: 3.748e-04\n","Loss: 3.744e-04\n","Loss: 3.739e-04\n","Loss: 3.733e-04\n","Loss: 3.727e-04\n","Loss: 3.723e-04\n","Loss: 3.719e-04\n","Loss: 3.717e-04\n","Loss: 3.713e-04\n","Loss: 3.717e-04\n","Loss: 3.710e-04\n","Loss: 3.706e-04\n","Loss: 3.702e-04\n","Loss: 3.699e-04\n","Loss: 3.695e-04\n","Loss: 3.691e-04\n","Loss: 3.686e-04\n","Loss: 3.680e-04\n","Loss: 3.674e-04\n","Loss: 3.759e-04\n","Loss: 3.672e-04\n","Loss: 3.666e-04\n","Loss: 3.663e-04\n","Loss: 3.659e-04\n","Loss: 3.654e-04\n","Loss: 3.650e-04\n","Loss: 3.646e-04\n","Loss: 3.643e-04\n","Loss: 3.639e-04\n","Loss: 3.636e-04\n","Loss: 3.633e-04\n","Loss: 3.644e-04\n","Loss: 3.629e-04\n","Loss: 3.625e-04\n","Loss: 3.620e-04\n","Loss: 3.617e-04\n","Loss: 3.615e-04\n","Loss: 3.613e-04\n","Loss: 3.610e-04\n","Loss: 3.609e-04\n","Loss: 3.603e-04\n","Loss: 3.602e-04\n","Loss: 3.598e-04\n","Loss: 3.593e-04\n","Loss: 3.586e-04\n","Loss: 3.576e-04\n","Loss: 3.568e-04\n","Loss: 3.563e-04\n","Loss: 3.559e-04\n","Loss: 3.553e-04\n","Loss: 3.548e-04\n","Loss: 3.543e-04\n","Loss: 3.538e-04\n","Loss: 3.532e-04\n","Loss: 3.524e-04\n","Loss: 3.513e-04\n","Loss: 3.514e-04\n","Loss: 3.510e-04\n","Loss: 3.507e-04\n","Loss: 3.504e-04\n","Loss: 3.501e-04\n","Loss: 3.495e-04\n","Loss: 3.494e-04\n","Loss: 3.487e-04\n","Loss: 3.484e-04\n","Loss: 3.479e-04\n","Loss: 3.475e-04\n","Loss: 3.472e-04\n","Loss: 3.468e-04\n","Loss: 3.465e-04\n","Loss: 3.462e-04\n","Loss: 3.458e-04\n","Loss: 3.452e-04\n","Loss: 3.505e-04\n","Loss: 3.451e-04\n","Loss: 3.448e-04\n","Loss: 3.445e-04\n","Loss: 3.444e-04\n","Loss: 3.442e-04\n","Loss: 3.440e-04\n","Loss: 3.436e-04\n","Loss: 3.435e-04\n","Loss: 3.428e-04\n","Loss: 3.423e-04\n","Loss: 3.418e-04\n","Loss: 3.413e-04\n","Loss: 3.406e-04\n","Loss: 3.400e-04\n","Loss: 3.392e-04\n","Loss: 3.387e-04\n","Loss: 3.382e-04\n","Loss: 3.376e-04\n","Loss: 3.373e-04\n","Loss: 3.371e-04\n","Loss: 3.366e-04\n","Loss: 3.362e-04\n","Loss: 3.355e-04\n","Loss: 3.350e-04\n","Loss: 3.343e-04\n","Loss: 3.341e-04\n","Loss: 3.335e-04\n","Loss: 3.333e-04\n","Loss: 3.330e-04\n","Loss: 3.328e-04\n","Loss: 3.324e-04\n","Loss: 3.321e-04\n","Loss: 3.316e-04\n","Loss: 3.313e-04\n","Loss: 3.308e-04\n","Loss: 3.305e-04\n","Loss: 3.303e-04\n","Loss: 3.300e-04\n","Loss: 3.297e-04\n","Loss: 3.295e-04\n","Loss: 3.293e-04\n","Loss: 3.291e-04\n","Loss: 3.289e-04\n","Loss: 3.287e-04\n","Loss: 3.285e-04\n","Loss: 3.283e-04\n","Loss: 3.281e-04\n","Loss: 3.279e-04\n","Loss: 3.275e-04\n","Loss: 3.268e-04\n","Loss: 3.262e-04\n","Loss: 3.269e-04\n","Loss: 3.260e-04\n","Loss: 3.253e-04\n","Loss: 3.248e-04\n","Loss: 3.245e-04\n","Loss: 3.243e-04\n","Loss: 3.242e-04\n","Loss: 3.241e-04\n","Loss: 3.240e-04\n","Loss: 3.239e-04\n","Loss: 3.238e-04\n","Loss: 3.237e-04\n","Loss: 3.235e-04\n","Loss: 3.674e-04\n","Loss: 3.234e-04\n","Loss: 3.232e-04\n","Loss: 3.231e-04\n","Loss: 3.230e-04\n","Loss: 3.229e-04\n","Loss: 3.231e-04\n","Loss: 3.228e-04\n","Loss: 3.227e-04\n","Loss: 3.226e-04\n","Loss: 3.225e-04\n","Loss: 3.224e-04\n","Loss: 3.223e-04\n","Loss: 3.221e-04\n","Loss: 3.221e-04\n","Loss: 3.220e-04\n","Loss: 3.218e-04\n","Loss: 3.223e-04\n","Loss: 3.218e-04\n","Loss: 3.217e-04\n","Loss: 3.216e-04\n","Loss: 3.215e-04\n","Loss: 3.213e-04\n","Loss: 3.211e-04\n","Loss: 3.210e-04\n","Loss: 3.209e-04\n","Loss: 3.208e-04\n","Loss: 3.207e-04\n","Loss: 3.206e-04\n","Loss: 3.203e-04\n","Loss: 3.199e-04\n","Loss: 3.197e-04\n","Loss: 3.195e-04\n","Loss: 3.193e-04\n","Loss: 3.190e-04\n","Loss: 3.187e-04\n","Loss: 3.183e-04\n","Loss: 3.179e-04\n","Loss: 3.176e-04\n","Loss: 3.172e-04\n","Loss: 3.170e-04\n","Loss: 3.166e-04\n","Loss: 3.174e-04\n","Loss: 3.164e-04\n","Loss: 3.161e-04\n","Loss: 3.157e-04\n","Loss: 3.150e-04\n","Loss: 3.145e-04\n","Loss: 3.140e-04\n","Loss: 3.135e-04\n","Loss: 3.133e-04\n","Loss: 3.128e-04\n","Loss: 3.125e-04\n","Loss: 3.122e-04\n","Loss: 3.119e-04\n","Loss: 3.126e-04\n","Loss: 3.117e-04\n","Loss: 3.114e-04\n","Loss: 3.108e-04\n","Loss: 3.102e-04\n","Loss: 3.096e-04\n","Loss: 3.097e-04\n","Loss: 3.092e-04\n","Loss: 3.091e-04\n","Loss: 3.085e-04\n","Loss: 3.083e-04\n","Loss: 3.081e-04\n","Loss: 3.080e-04\n","Loss: 3.078e-04\n","Loss: 3.076e-04\n","INFO:tensorflow:Optimization terminated with:\n","  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n","  Objective function value: 0.000308\n","  Number of iterations: 3000\n","  Number of functions evaluations: 3190\n","Training time: 1403.5055\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"ZTCiovfLzWbQ","executionInfo":{"status":"ok","timestamp":1608270624259,"user_tz":360,"elapsed":1037,"user":{"displayName":"duy pham","photoUrl":"","userId":"13182125700906094592"}}},"source":["a_file = open(\"Loss21.txt\", \"w\")\r\n","for row in np.array(model.lossHistogram).reshape(len(model.lossHistogram), 1):\r\n","    np.savetxt(a_file, row)\r\n","a_file.close()"],"execution_count":73,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"06vK6licISxa","executionInfo":{"status":"ok","timestamp":1608002140695,"user_tz":-420,"elapsed":969,"user":{"displayName":"duy pham","photoUrl":"","userId":"13182125700906094592"}},"outputId":"c37e4abf-5526-4d24-fad6-7141213171e7"},"source":["epochs"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2593"]},"metadata":{"tags":[]},"execution_count":36}]},{"cell_type":"code","metadata":{"id":"fuGpp0je41Yl","executionInfo":{"status":"ok","timestamp":1608270627495,"user_tz":360,"elapsed":990,"user":{"displayName":"duy pham","photoUrl":"","userId":"13182125700906094592"}}},"source":["def exact_solution(x, y, t):\n","    u = tf.math.exp(t)*tf.math.sin(np.pi*x)*tf.math.sin(np.pi*y)\n","    return u"],"execution_count":74,"outputs":[]},{"cell_type":"code","metadata":{"id":"SP-mJglb4VIe"},"source":["def flatArr(x):\n","    y = []\n","    for row in x:\n","        for el in row:\n","            y.append(el)\n","    return np.array(y).flatten()\n","\n","def splitData(data):\n","    x = []\n","    y = []\n","    xb = []\n","    yb = []\n","    ub = []\n","    u = []\n","    for row in data:\n","        if (row[0] == 0. or row[1] == 0. or row[0] == 1. or row[1] == 1.):\n","            xb.append(row[0])\n","            yb.append(row[1])\n","            ub.append(0.0)\n","        else:\n","            x.append(row[0])\n","            y.append(row[1])\n","            u.append(round(np.sin(np.pi*row[0])*np.sin(np.pi*row[1]), 6))\n","    return np.array(x), np.array(y), np.array(u), np.array(xb), np.array(yb), np.array(ub)\n","\n","def sample(T, delta_t, data):\n","    xi,yi,ui,xb,yb,ub = splitData(data)\n","    x_arr = np.array([])\n","    y_arr = np.array([])\n","    NT = np.int(T/delta_t)\n","    t = []\n","    for i in range(NT):\n","        t.append([round((i+1)*delta_t,6) for e in range(xi.size)])\n","        x_arr = np.concatenate((x_arr, xi))\n","        y_arr = np.concatenate((y_arr, yi))\n","    t = flatArr(t)\n","    tb = []\n","    xb_arr = np.array([])\n","    yb_arr = np.array([])\n","    for i in range(NT+1):\n","        tb.append([round(i*delta_t,6) for e in range(xb.size)])\n","        xb_arr = np.concatenate((xb_arr, xb))\n","        yb_arr = np.concatenate((yb_arr, yb))\n","    tb = flatArr(tb)\n","    ti = np.array([0.0 for e in range(xi.size)])\n","    ub = np.array([0.0 for e in xb_arr])\n","\n","    return x_arr, y_arr, t, xi, yi, ti, ui, xb_arr, yb_arr, tb, ub"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"49VsFHof3D3i"},"source":["dataset = np.genfromtxt('triangle_data_10_10.txt', delimiter=',')\n","x, y, t, xi, yi, ti, ui, xb, yb, tb, ub = sample(1.0, 0.1, dataset)\n","x = x.reshape((x.size, 1, 1))\n","y = y.reshape((y.size, 1, 1))\n","t = t.reshape((t.size, 1, 1))\n","xb = xb.reshape((xb.size, 1, 1))\n","yb = yb.reshape((yb.size, 1, 1))\n","tb = tb.reshape((tb.size, 1, 1))\n","ub = ub.reshape((ub.size, 1))\n","xi = xi.reshape((xi.size, 1, 1))\n","yi = yi.reshape((yi.size, 1, 1))\n","ti = ti.reshape((ti.size, 1, 1))\n","ui = ui.reshape((ui.size, 1))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BTAfM8WWZajG","executionInfo":{"status":"ok","timestamp":1608270631713,"user_tz":360,"elapsed":964,"user":{"displayName":"duy pham","photoUrl":"","userId":"13182125700906094592"}}},"source":["dataset = np.genfromtxt('data_2000.csv', delimiter=',')\r\n","# x, y, xb, yb, ub, vb = splitData(dataset)\r\n","x = dataset[:,0]\r\n","x = x.reshape((x.size, 1, 1))\r\n","y = dataset[:,1]\r\n","y = y.reshape((y.size, 1, 1))\r\n","t = dataset[:,2]\r\n","t = t.reshape((t.size, 1, 1))\r\n","xb = dataset[:,3]\r\n","xb = xb.reshape((xb.size, 1, 1))\r\n","yb = dataset[:,4]\r\n","yb = yb.reshape((yb.size, 1, 1))\r\n","tb = dataset[:,5]\r\n","tb = tb.reshape((tb.size, 1, 1))\r\n","ub = dataset[:,6]\r\n","ub = ub.reshape((ub.size, 1))\r\n","xi = dataset[:,7]\r\n","xi = xi.reshape((xi.size, 1, 1))\r\n","yi = dataset[:,8]\r\n","yi = yi.reshape((yi.size, 1, 1))\r\n","ti = dataset[:,9]\r\n","ti = ti.reshape((ti.size, 1, 1))\r\n","ui = dataset[:,10]\r\n","ui = ui.reshape((ui.size, 1))"],"execution_count":75,"outputs":[]},{"cell_type":"code","metadata":{"id":"y8I1fh4-5y_N","executionInfo":{"status":"ok","timestamp":1608270636017,"user_tz":360,"elapsed":3976,"user":{"displayName":"duy pham","photoUrl":"","userId":"13182125700906094592"}}},"source":["u_e = exact_solution(x, y, t)\n","u_e = tf.reshape(u_e, [x.size, 1])\n","u_pred = model.predict(x, y, t)\n","ub_pred = model.predict(xb, yb, tb)\n","ui_pred = model.predict(xi, yi, ti)"],"execution_count":76,"outputs":[]},{"cell_type":"code","metadata":{"id":"DkuPyoNCTuuz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608270637054,"user_tz":360,"elapsed":4185,"user":{"displayName":"duy pham","photoUrl":"","userId":"13182125700906094592"}},"outputId":"329a2848-4321-4e4a-854e-7c3d2d900c25"},"source":["LossL2 = tf.reduce_mean(tf.square(u_pred - u_e)) + tf.reduce_mean(tf.square(ub_pred - ub)) + tf.reduce_mean(tf.square(ui_pred - ui))\n","with tf.Session() as sess:\n","    result = LossL2.eval()\n","\n","    print(result) \n","\n","    print(type(result))"],"execution_count":77,"outputs":[{"output_type":"stream","text":["0.00011957960237262262\n","<class 'numpy.float64'>\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hITLqCWDEJVG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608270637955,"user_tz":360,"elapsed":3782,"user":{"displayName":"duy pham","photoUrl":"","userId":"13182125700906094592"}},"outputId":"dda61115-930f-4228-9b5f-68bdbbbecc2d"},"source":["LossL2= tf.math.sqrt(LossL2)\n","with tf.Session() as sess:\n","    result = LossL2.eval()\n","\n","    print(result) \n","\n","    print(type(result))"],"execution_count":78,"outputs":[{"output_type":"stream","text":["0.010935245876185072\n","<class 'numpy.float64'>\n"],"name":"stdout"}]}]}